{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac113c5f-bf08-4b7b-a649-f397c225e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df=pd.read_csv(\"merged_features_drop_cleaned_train_data.csv\")\n",
    "test_df=pd.read_csv(\"merged_features_drop_cleaned_test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56c59d84-1a83-4134-ac85-1bbf61461e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hussain\\AppData\\Local\\Temp\\ipykernel_16832\\3727695354.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\hussain\\AppData\\Local\\Temp\\ipykernel_16832\\3727695354.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, using forward fill. Adjust based on your data's characteristics.\n",
    "train_df.fillna(method='ffill', inplace=True)\n",
    "test_df.fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ce763aa-0155-4df4-b1d5-70de35e0b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status                          0\n",
       "departure.iataCode              0\n",
       "departure.icaoCode              0\n",
       "departure.terminal              0\n",
       "departure.scheduledTime         0\n",
       "departure.estimatedTime         0\n",
       "departure.actualTime            0\n",
       "departure.estimatedRunway       0\n",
       "departure.actualRunway          0\n",
       "arrival.scheduledTime           0\n",
       "arrival.estimatedTime           0\n",
       "airline.iataCode                0\n",
       "airline.icaoCode                0\n",
       "flight.number                   0\n",
       "flight.iataNumber               0\n",
       "flight.icaoNumber               0\n",
       "arrival.actualTime              0\n",
       "arrival.estimatedRunway      1028\n",
       "arrival.actualRunway            0\n",
       "departure.delay_minutes         0\n",
       "departure.hour_of_day           0\n",
       "departure.month                 0\n",
       "status_encoded                  0\n",
       "Departure_Date                  0\n",
       "Departure_Month                 0\n",
       "Departure_Day                   0\n",
       "Departure_Hour                  0\n",
       "Month                           0\n",
       "Day                             0\n",
       "Temperature (°F) Max            0\n",
       "Temperature (°F) Avg            0\n",
       "Temperature (°F) Min            0\n",
       "Dew Point (°F) Max              0\n",
       "Dew Point (°F) Avg              0\n",
       "Dew Point (°F) Min              0\n",
       "Humidity (%) Max                0\n",
       "Humidity (%) Avg                0\n",
       "Humidity (%) Min                0\n",
       "Wind Speed (mph) Max            0\n",
       "Wind Speed (mph) Avg            0\n",
       "Wind Speed (mph) Min            0\n",
       "Pressure (in) Max               0\n",
       "Pressure (in) Avg               0\n",
       "Pressure (in) Min               0\n",
       "Precipitation (in) Total        0\n",
       "delay_status                    0\n",
       "delay_category                  1\n",
       "airline.name                    0\n",
       "departure.day_of_week           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e444e-be1b-4373-ab52-db9880c7c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_cols = [\n",
    "    'departure.estimatedTime',\n",
    "    'departure.actualTime']\n",
    "\n",
    "for col in datetime_cols:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors='coerce')\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors='coerce')\n",
    "\n",
    "# After conversion, handle any new missing values introduced by errors='coerce'\n",
    "train_df.fillna(method='ffill', inplace=True)\n",
    "#test_df.fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eaf7f3-9281-4190-93db-1b8e606db804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For preprocessing and modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix,\n",
    "                             mean_absolute_error, mean_squared_error)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================\n",
    "# PHASE 3: Analytical and Predictive Tasks\n",
    "# ==============================================\n",
    "\n",
    "# 1. Load Data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(train, test):\n",
    "    # Handle missing values\n",
    "    train.fillna(method='ffill', inplace=True)\n",
    "    test.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # Convert object time columns to datetime\n",
    "    datetime_cols = [\n",
    "        'departure.scheduledTime',\n",
    "        'departure.estimatedTime',\n",
    "        'departure.actualTime',\n",
    "        'departure.estimatedRunway',\n",
    "        'departure.actualRunway',\n",
    "        'arrival.scheduledTime',\n",
    "        'arrival.estimatedTime',\n",
    "        'arrival.actualTime',\n",
    "        'arrival.estimatedRunway',\n",
    "        'arrival.actualRunway'\n",
    "    ]\n",
    "    \n",
    "    for col in datetime_cols:\n",
    "        # Convert to datetime, coerce errors to NaT\n",
    "        train[col] = pd.to_datetime(train[col], errors='coerce')\n",
    "        test[col] = pd.to_datetime(test[col], errors='coerce')\n",
    "    \n",
    "    # After conversion, handle any new missing values\n",
    "    train.fillna(method='ffill', inplace=True)\n",
    "    test.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # Feature Engineering: Extract datetime features\n",
    "    def extract_datetime_features(df, datetime_columns):\n",
    "        for col in datetime_columns:\n",
    "            df[f\"{col}_hour\"] = df[col].dt.hour\n",
    "            df[f\"{col}_minute\"] = df[col].dt.minute\n",
    "            df[f\"{col}_dayofweek\"] = df[col].dt.dayofweek\n",
    "            df[f\"{col}_day\"] = df[col].dt.day\n",
    "            df[f\"{col}_month\"] = df[col].dt.month\n",
    "            df[f\"{col}_year\"] = df[col].dt.year\n",
    "        return df\n",
    "    \n",
    "    train = extract_datetime_features(train, datetime_cols)\n",
    "    test = extract_datetime_features(test, datetime_cols)\n",
    "    \n",
    "    # Drop original datetime columns if not needed\n",
    "    train.drop(columns=datetime_cols, inplace=True)\n",
    "    test.drop(columns=datetime_cols, inplace=True)\n",
    "    \n",
    "    # Encode categorical variables if necessary\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    categorical_features.remove('delay_status')  # Assuming 'delay_status' is similar to target\n",
    "    categorical_features.remove('delay_category')  # Will be used for multi-class\n",
    "    categorical_features.remove('delay')  # If present\n",
    "    categorical_features = [col for col in categorical_features if col not in ['binary_target', 'multi_target']]\n",
    "    \n",
    "    numerical_features = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    numerical_features.remove('departure.delay_minutes')  # Target for regression\n",
    "    \n",
    "    # Remove target variables from features\n",
    "    X_train = train.drop(['departure.delay_minutes'], axis=1)\n",
    "    X_test = test.copy()\n",
    "    \n",
    "    return X_train, test, numerical_features, categorical_features\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_full, X_test_full, numerical_features, categorical_features = preprocess_data(train_df, test_df)\n",
    "\n",
    "# ==============================================\n",
    "# 3. Define Target Variables\n",
    "# ==============================================\n",
    "\n",
    "# Binary Classification: 'on-time' vs 'delayed'\n",
    "X_train_full['binary_target'] = X_train_full['departure.delay_minutes'].apply(lambda x: 'on-time' if x == 0 else 'delayed')\n",
    "\n",
    "# Multi-Class Classification: No Delay, Short Delay, Moderate Delay, Long Delay\n",
    "def categorize_delay(x):\n",
    "    if x == 0:\n",
    "        return 'No Delay'\n",
    "    elif x < 45:\n",
    "        return 'Short Delay'\n",
    "    elif 45 <= x <= 175:\n",
    "        return 'Moderate Delay'\n",
    "    else:\n",
    "        return 'Long Delay'\n",
    "\n",
    "X_train_full['multi_target'] = X_train_full['departure.delay_minutes'].apply(categorize_delay)\n",
    "\n",
    "# Regression Target: 'departure.delay_minutes'\n",
    "y_reg = X_train_full['departure.delay_minutes']\n",
    "\n",
    "# Prepare features for Binary and Multi-Class Classification\n",
    "X_bin = X_train_full.drop(['departure.delay_minutes', 'multi_target'], axis=1)\n",
    "y_bin = X_train_full['binary_target']\n",
    "\n",
    "X_multi = X_train_full.drop(['departure.delay_minutes', 'binary_target'], axis=1)\n",
    "y_multi = X_train_full['multi_target']\n",
    "\n",
    "# ==============================================\n",
    "# 4. Define Preprocessing Pipelines\n",
    "# ==============================================\n",
    "\n",
    "# Preprocessor for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# ==============================================\n",
    "# 5. Binary Classification\n",
    "# ==============================================\n",
    "\n",
    "# Train-Test Split for Binary Classification\n",
    "X_train_bin, X_val_bin, y_train_bin, y_val_bin = train_test_split(\n",
    "    X_bin, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n",
    "\n",
    "# Define Binary Classification Pipeline\n",
    "binary_clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the Binary Classification Model\n",
    "binary_clf_pipeline.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Predict on Validation Set\n",
    "y_pred_bin = binary_clf_pipeline.predict(X_val_bin)\n",
    "\n",
    "# Evaluate Binary Classification\n",
    "print(\"=== Binary Classification Metrics ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_bin, y_pred_bin))\n",
    "print(\"Precision:\", precision_score(y_val_bin, y_pred_bin, pos_label='delayed'))\n",
    "print(\"Recall:\", recall_score(y_val_bin, y_pred_bin, pos_label='delayed'))\n",
    "print(\"F1-Score:\", f1_score(y_val_bin, y_pred_bin, pos_label='delayed'))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_bin, y_pred_bin, labels=['on-time', 'delayed']))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_bin, y_pred_bin))\n",
    "\n",
    "# ==============================================\n",
    "# 6. Multi-Class Classification\n",
    "# ==============================================\n",
    "\n",
    "# Train-Test Split for Multi-Class Classification\n",
    "X_train_multi, X_val_multi, y_train_multi, y_val_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi)\n",
    "\n",
    "# Define Multi-Class Classification Pipeline\n",
    "multi_clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the Multi-Class Classification Model\n",
    "multi_clf_pipeline.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Predict on Validation Set\n",
    "y_pred_multi = multi_clf_pipeline.predict(X_val_multi)\n",
    "\n",
    "# Evaluate Multi-Class Classification\n",
    "print(\"=== Multi-Class Classification Metrics ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_multi, y_pred_multi))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_multi, y_pred_multi))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_multi, y_pred_multi))\n",
    "\n",
    "# ==============================================\n",
    "# 7. Regression Analysis\n",
    "# ==============================================\n",
    "\n",
    "# Train-Test Split for Regression\n",
    "X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(\n",
    "    X_train_full.drop(['binary_target', 'multi_target'], axis=1),\n",
    "    y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define Regression Pipeline\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the Regression Model\n",
    "reg_pipeline.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict on Validation Set\n",
    "y_pred_reg = reg_pipeline.predict(X_val_reg)\n",
    "\n",
    "# Evaluate Regression\n",
    "mae = mean_absolute_error(y_val_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_reg, y_pred_reg))\n",
    "print(\"=== Regression Metrics ===\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# ==============================================\n",
    "# PHASE 4: Model Optimization and Evaluation\n",
    "# ==============================================\n",
    "\n",
    "# 1. Hyperparameter Tuning for Binary Classification\n",
    "param_grid_bin = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_bin = GridSearchCV(binary_clf_pipeline, param_grid_bin, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid_search_bin.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "print(\"=== Best Parameters for Binary Classification ===\")\n",
    "print(grid_search_bin.best_params_)\n",
    "\n",
    "best_binary_model = grid_search_bin.best_estimator_\n",
    "\n",
    "# Evaluate Best Binary Model\n",
    "y_pred_bin_best = best_binary_model.predict(X_val_bin)\n",
    "print(\"=== Binary Classification Metrics After Hyperparameter Tuning ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_bin, y_pred_bin_best))\n",
    "print(\"Precision:\", precision_score(y_val_bin, y_pred_bin_best, pos_label='delayed'))\n",
    "print(\"Recall:\", recall_score(y_val_bin, y_pred_bin_best, pos_label='delayed'))\n",
    "print(\"F1-Score:\", f1_score(y_val_bin, y_pred_bin_best, pos_label='delayed'))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_bin, y_pred_bin_best, labels=['on-time', 'delayed']))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_bin, y_pred_bin_best))\n",
    "\n",
    "# 2. K-Fold Cross-Validation for Regression\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_reg = cross_val_score(reg_pipeline, X_train_reg, y_train_reg, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores_reg = np.sqrt(-cv_scores_reg)\n",
    "print(\"=== Regression Cross-Validation RMSE ===\")\n",
    "print(\"Scores:\", rmse_scores_reg)\n",
    "print(\"Mean RMSE:\", rmse_scores_reg.mean())\n",
    "\n",
    "# 3. Model Comparison (Example: Random Forest vs. Logistic Regression vs. SVM for Binary Classification)\n",
    "\n",
    "# Define multiple models\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ]),\n",
    "    'SVM': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))\n",
    "    ]),\n",
    "    'DecisionTree': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "    ]),\n",
    "    'KNN': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GaussianNB())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_bin, y_bin, cv=5, scoring='f1', n_jobs=-1)\n",
    "    print(f\"{name} F1 Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# Choose the best performing model based on cross-validation scores\n",
    "# For demonstration, assume RandomForest performed best\n",
    "\n",
    "# ==============================================\n",
    "# PHASE 5: Model Testing and Submission\n",
    "# ==============================================\n",
    "\n",
    "# 1. Make Predictions on the Test Dataset\n",
    "\n",
    "# Prepare the test set features (ensure same preprocessing)\n",
    "test_X = X_test_full.drop(['departure.delay_minutes', 'binary_target', 'multi_target'], axis=1, errors='ignore')\n",
    "\n",
    "# Binary Classification Prediction using best_binary_model\n",
    "test_pred_bin = best_binary_model.predict(test_X)\n",
    "\n",
    "# Multi-Class Classification Prediction (if you have optimized multi-class model)\n",
    "# Assuming you have a best_multi_model (similar to best_binary_model)\n",
    "# For this example, we'll use the previously trained multi_clf_pipeline\n",
    "test_pred_multi = multi_clf_pipeline.predict(test_X)\n",
    "\n",
    "# Regression Prediction using reg_pipeline\n",
    "test_pred_reg = reg_pipeline.predict(test_X)\n",
    "\n",
    "# 2. Save Predictions in Kaggle Submission Format\n",
    "\n",
    "# Define a function to create submission files\n",
    "def create_submission(test_df, predictions, submission_type='binary'):\n",
    "    # Ensure that the necessary columns are present in test_df\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time'\n",
    "    ]\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    for col in required_columns:\n",
    "        if col not in test_df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    submission = test_df[required_columns].copy()\n",
    "    \n",
    "    if submission_type == 'binary':\n",
    "        # Convert predictions to string format\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'multi':\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'regression':\n",
    "        # Convert delay minutes to integer or keep as float based on Kaggle requirements\n",
    "        submission['Delay'] = predictions.round().astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid submission type. Choose from 'binary', 'multi', or 'regression'.\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# Create Binary Classification Submission\n",
    "submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "\n",
    "# Create Multi-Class Classification Submission\n",
    "submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "\n",
    "# Create Regression Submission\n",
    "submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "\n",
    "# ==============================================\n",
    "# Additional: Feature Importance Plot (Optional)\n",
    "# ==============================================\n",
    "\n",
    "# Plot feature importances for Binary Classification\n",
    "def plot_feature_importances(model, preprocessor, numerical_features, categorical_features, top_n=20):\n",
    "    # Get feature names after preprocessing\n",
    "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    ohe_features = ohe.get_feature_names_out(categorical_features)\n",
    "    feature_names = numerical_features + list(ohe_features)\n",
    "    \n",
    "    # Get feature importances from the model\n",
    "    importances = model.named_steps['classifier'].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=importances[indices][:top_n], y=np.array(feature_names)[indices][:top_n])\n",
    "    plt.title(f\"Top {top_n} Feature Importances\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot feature importances for best_binary_model\n",
    "plot_feature_importances(best_binary_model, preprocessor, numerical_features, categorical_features, top_n=20)\n",
    "\n",
    "# ==============================================\n",
    "# END OF SCRIPT\n",
    "# ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9869fd09-a111-4f1a-a57f-1d3448c05e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>departure.iataCode</th>\n",
       "      <th>departure.icaoCode</th>\n",
       "      <th>departure.scheduledTime</th>\n",
       "      <th>departure.estimatedRunway</th>\n",
       "      <th>departure.actualRunway</th>\n",
       "      <th>arrival.scheduledTime</th>\n",
       "      <th>arrival.estimatedTime</th>\n",
       "      <th>airline.iataCode</th>\n",
       "      <th>airline.icaoCode</th>\n",
       "      <th>flight.number</th>\n",
       "      <th>flight.iataNumber</th>\n",
       "      <th>flight.icaoNumber</th>\n",
       "      <th>departure.terminal</th>\n",
       "      <th>arrival.actualTime</th>\n",
       "      <th>arrival.estimatedRunway</th>\n",
       "      <th>arrival.actualRunway</th>\n",
       "      <th>departure.hour_of_day</th>\n",
       "      <th>departure.month</th>\n",
       "      <th>status_encoded</th>\n",
       "      <th>departure.day_of_week_Monday</th>\n",
       "      <th>departure.day_of_week_Saturday</th>\n",
       "      <th>departure.day_of_week_Sunday</th>\n",
       "      <th>departure.day_of_week_Thursday</th>\n",
       "      <th>departure.day_of_week_Tuesday</th>\n",
       "      <th>departure.day_of_week_Wednesday</th>\n",
       "      <th>airline.name_air arabia</th>\n",
       "      <th>airline.name_air canada</th>\n",
       "      <th>airline.name_air china ltd</th>\n",
       "      <th>airline.name_air france</th>\n",
       "      <th>airline.name_air mauritius</th>\n",
       "      <th>airline.name_airact</th>\n",
       "      <th>airline.name_airblue</th>\n",
       "      <th>airline.name_airsial</th>\n",
       "      <th>airline.name_alitalia</th>\n",
       "      <th>airline.name_american airlines</th>\n",
       "      <th>airline.name_ariana afghan airlines</th>\n",
       "      <th>airline.name_asiana airlines</th>\n",
       "      <th>airline.name_azal azerbaijan airlines</th>\n",
       "      <th>airline.name_batik air</th>\n",
       "      <th>airline.name_british airways</th>\n",
       "      <th>airline.name_cham wings airlines</th>\n",
       "      <th>airline.name_china southern airlines</th>\n",
       "      <th>airline.name_danish air</th>\n",
       "      <th>airline.name_egyptair</th>\n",
       "      <th>airline.name_emirates</th>\n",
       "      <th>airline.name_empty</th>\n",
       "      <th>airline.name_ethiopian airlines</th>\n",
       "      <th>airline.name_etihad airways</th>\n",
       "      <th>airline.name_evelop airlines</th>\n",
       "      <th>airline.name_fai rent-a-jet</th>\n",
       "      <th>airline.name_fitsair</th>\n",
       "      <th>airline.name_fly baghdad</th>\n",
       "      <th>airline.name_flydubai</th>\n",
       "      <th>airline.name_flyjinnah</th>\n",
       "      <th>airline.name_flynas</th>\n",
       "      <th>airline.name_georgian airlines</th>\n",
       "      <th>airline.name_gulf air</th>\n",
       "      <th>airline.name_harmony jets</th>\n",
       "      <th>airline.name_hi fly</th>\n",
       "      <th>...</th>\n",
       "      <th>airline.name_klm</th>\n",
       "      <th>airline.name_kuwait airways</th>\n",
       "      <th>airline.name_lion air</th>\n",
       "      <th>airline.name_mahan air</th>\n",
       "      <th>airline.name_malaysia airlines</th>\n",
       "      <th>airline.name_maleth-aero</th>\n",
       "      <th>airline.name_malindo air</th>\n",
       "      <th>airline.name_nomadic aviation</th>\n",
       "      <th>airline.name_oman air</th>\n",
       "      <th>airline.name_pakistan international airlines</th>\n",
       "      <th>airline.name_pegasus</th>\n",
       "      <th>airline.name_privilege style</th>\n",
       "      <th>airline.name_qatar airways</th>\n",
       "      <th>airline.name_redstar aviation</th>\n",
       "      <th>airline.name_royal air maroc</th>\n",
       "      <th>airline.name_royal jordanian</th>\n",
       "      <th>airline.name_rwandair</th>\n",
       "      <th>airline.name_salamair</th>\n",
       "      <th>airline.name_saudia</th>\n",
       "      <th>airline.name_scat airlines</th>\n",
       "      <th>airline.name_serene air</th>\n",
       "      <th>airline.name_silk way airlines</th>\n",
       "      <th>airline.name_smartlynx airlines</th>\n",
       "      <th>airline.name_smartwings</th>\n",
       "      <th>airline.name_somon air</th>\n",
       "      <th>airline.name_srilankan airlines</th>\n",
       "      <th>airline.name_swiss air-ambulance</th>\n",
       "      <th>airline.name_thai airways international</th>\n",
       "      <th>airline.name_turkish airlines</th>\n",
       "      <th>airline.name_uls airlines cargo</th>\n",
       "      <th>airline.name_virgin australia</th>\n",
       "      <th>airline.name_yto cargo airlines</th>\n",
       "      <th>Departure_Date</th>\n",
       "      <th>Departure_Month</th>\n",
       "      <th>Departure_Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Temperature (°F) Max</th>\n",
       "      <th>Temperature (°F) Avg</th>\n",
       "      <th>Temperature (°F) Min</th>\n",
       "      <th>Dew Point (°F) Max</th>\n",
       "      <th>Dew Point (°F) Avg</th>\n",
       "      <th>Dew Point (°F) Min</th>\n",
       "      <th>Humidity (%) Max</th>\n",
       "      <th>Humidity (%) Avg</th>\n",
       "      <th>Humidity (%) Min</th>\n",
       "      <th>Wind Speed (mph) Max</th>\n",
       "      <th>Wind Speed (mph) Avg</th>\n",
       "      <th>Wind Speed (mph) Min</th>\n",
       "      <th>Pressure (in) Max</th>\n",
       "      <th>Pressure (in) Avg</th>\n",
       "      <th>Pressure (in) Min</th>\n",
       "      <th>Precipitation (in) Total</th>\n",
       "      <th>Departure_Hour</th>\n",
       "      <th>Departure_DayOfWeek_Monday</th>\n",
       "      <th>Departure_DayOfWeek_Saturday</th>\n",
       "      <th>Departure_DayOfWeek_Sunday</th>\n",
       "      <th>Departure_DayOfWeek_Thursday</th>\n",
       "      <th>Departure_DayOfWeek_Tuesday</th>\n",
       "      <th>Departure_DayOfWeek_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-07-17 20:35:00</td>\n",
       "      <td>2023-07-17 20:46:00</td>\n",
       "      <td>2023-07-17 20:46:00</td>\n",
       "      <td>2023-07-17 22:20:00</td>\n",
       "      <td>2023-07-17 22:12:00</td>\n",
       "      <td>9p</td>\n",
       "      <td>fjl</td>\n",
       "      <td>847</td>\n",
       "      <td>9p847</td>\n",
       "      <td>fjl847</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-07-17 22:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-17 22:20:00</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jul 17</td>\n",
       "      <td>Jul</td>\n",
       "      <td>17</td>\n",
       "      <td>Jul</td>\n",
       "      <td>17.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-07-27 08:00:00</td>\n",
       "      <td>2023-07-17 20:46:00</td>\n",
       "      <td>2023-07-27 08:00:00</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>2023-07-17 22:12:00</td>\n",
       "      <td>pk</td>\n",
       "      <td>pia</td>\n",
       "      <td>725</td>\n",
       "      <td>pk725</td>\n",
       "      <td>pia725</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jul 27</td>\n",
       "      <td>Jul</td>\n",
       "      <td>27</td>\n",
       "      <td>Jul</td>\n",
       "      <td>27.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-07-27 08:00:00</td>\n",
       "      <td>2023-07-17 20:46:00</td>\n",
       "      <td>2023-07-27 08:00:00</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>2023-07-17 22:12:00</td>\n",
       "      <td>et</td>\n",
       "      <td>eth</td>\n",
       "      <td>4359</td>\n",
       "      <td>et4359</td>\n",
       "      <td>eth4359</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-27 10:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jul 27</td>\n",
       "      <td>Jul</td>\n",
       "      <td>27</td>\n",
       "      <td>Jul</td>\n",
       "      <td>27.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-07-28 16:45:00</td>\n",
       "      <td>2023-07-17 20:46:00</td>\n",
       "      <td>2023-07-28 16:45:00</td>\n",
       "      <td>2023-07-28 20:30:00</td>\n",
       "      <td>2023-07-17 22:12:00</td>\n",
       "      <td>pa</td>\n",
       "      <td>abq</td>\n",
       "      <td>470</td>\n",
       "      <td>pa470</td>\n",
       "      <td>abq470</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-28 20:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-28 20:30:00</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jul 28</td>\n",
       "      <td>Jul</td>\n",
       "      <td>28</td>\n",
       "      <td>Jul</td>\n",
       "      <td>28.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>86.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-07-19 04:15:00</td>\n",
       "      <td>2023-07-19 04:18:00</td>\n",
       "      <td>2023-07-19 04:18:00</td>\n",
       "      <td>2023-07-19 06:35:00</td>\n",
       "      <td>2023-07-19 06:08:00</td>\n",
       "      <td>kl</td>\n",
       "      <td>klm</td>\n",
       "      <td>3932</td>\n",
       "      <td>kl3932</td>\n",
       "      <td>klm3932</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-19 06:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-19 06:35:00</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jul 19</td>\n",
       "      <td>Jul</td>\n",
       "      <td>19</td>\n",
       "      <td>Jul</td>\n",
       "      <td>19.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>84.4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-11-23 23:15:00</td>\n",
       "      <td>2023-11-23 23:27:00</td>\n",
       "      <td>2023-11-23 23:27:00</td>\n",
       "      <td>2023-11-24 02:05:00</td>\n",
       "      <td>2023-11-24 01:34:00</td>\n",
       "      <td>pa</td>\n",
       "      <td>abq</td>\n",
       "      <td>412</td>\n",
       "      <td>pa412</td>\n",
       "      <td>abq412</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-24 01:34:00</td>\n",
       "      <td>2023-11-24 00:34:00</td>\n",
       "      <td>2023-11-24 02:05:00</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nov 23</td>\n",
       "      <td>Nov</td>\n",
       "      <td>23</td>\n",
       "      <td>Nov</td>\n",
       "      <td>23.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-11-25 18:45:00</td>\n",
       "      <td>2023-11-25 19:05:00</td>\n",
       "      <td>2023-11-25 19:05:00</td>\n",
       "      <td>2023-11-25 22:05:00</td>\n",
       "      <td>2023-11-25 22:09:00</td>\n",
       "      <td>pk</td>\n",
       "      <td>pia</td>\n",
       "      <td>859</td>\n",
       "      <td>pk859</td>\n",
       "      <td>pia859</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-25 22:09:00</td>\n",
       "      <td>2023-11-24 00:34:00</td>\n",
       "      <td>2023-11-25 22:05:00</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nov 25</td>\n",
       "      <td>Nov</td>\n",
       "      <td>25</td>\n",
       "      <td>Nov</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-11-25 02:55:00</td>\n",
       "      <td>2023-11-25 03:07:00</td>\n",
       "      <td>2023-11-25 03:07:00</td>\n",
       "      <td>2023-11-25 05:05:00</td>\n",
       "      <td>2023-11-25 04:33:00</td>\n",
       "      <td>ba</td>\n",
       "      <td>baw</td>\n",
       "      <td>6187</td>\n",
       "      <td>ba6187</td>\n",
       "      <td>baw6187</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-25 04:33:00</td>\n",
       "      <td>2023-11-24 00:34:00</td>\n",
       "      <td>2023-11-25 05:05:00</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nov 25</td>\n",
       "      <td>Nov</td>\n",
       "      <td>25</td>\n",
       "      <td>Nov</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-11-27 08:35:00</td>\n",
       "      <td>2023-11-25 03:07:00</td>\n",
       "      <td>2023-11-27 08:35:00</td>\n",
       "      <td>2023-11-27 10:45:00</td>\n",
       "      <td>2023-11-25 04:33:00</td>\n",
       "      <td>wy</td>\n",
       "      <td>oma</td>\n",
       "      <td>6032</td>\n",
       "      <td>wy6032</td>\n",
       "      <td>oma6032</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-27 10:45:00</td>\n",
       "      <td>2023-11-24 00:34:00</td>\n",
       "      <td>2023-11-27 10:45:00</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nov 27</td>\n",
       "      <td>Nov</td>\n",
       "      <td>27</td>\n",
       "      <td>Nov</td>\n",
       "      <td>27.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>2023-11-26 01:45:00</td>\n",
       "      <td>2023-11-25 03:07:00</td>\n",
       "      <td>2023-11-26 01:45:00</td>\n",
       "      <td>2023-11-26 04:15:00</td>\n",
       "      <td>2023-11-25 04:33:00</td>\n",
       "      <td>w5</td>\n",
       "      <td>irm</td>\n",
       "      <td>1194</td>\n",
       "      <td>w51194</td>\n",
       "      <td>irm1194</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-26 04:15:00</td>\n",
       "      <td>2023-11-24 00:34:00</td>\n",
       "      <td>2023-11-26 04:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nov 26</td>\n",
       "      <td>Nov</td>\n",
       "      <td>26</td>\n",
       "      <td>Nov</td>\n",
       "      <td>26.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14982 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status departure.iataCode  ... Departure_DayOfWeek_Tuesday Departure_DayOfWeek_Wednesday\n",
       "0           0                lhe  ...                       False                         False\n",
       "1           0                lhe  ...                       False                         False\n",
       "2           0                lhe  ...                       False                         False\n",
       "3           2                lhe  ...                       False                         False\n",
       "4           0                lhe  ...                       False                          True\n",
       "...       ...                ...  ...                         ...                           ...\n",
       "14977       0                lhe  ...                       False                         False\n",
       "14978       0                lhe  ...                       False                         False\n",
       "14979       0                lhe  ...                       False                         False\n",
       "14980       0                lhe  ...                       False                         False\n",
       "14981       0                lhe  ...                       False                         False\n",
       "\n",
       "[14982 rows x 127 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3559dacf-28e0-4805-91ef-9e52f3c6762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       status departure.iataCode  ... departure.actualTime_month departure.actualTime_year\n",
      "0           0                lhe  ...                          7                      2023\n",
      "1           0                lhe  ...                          7                      2023\n",
      "2           0                lhe  ...                          7                      2023\n",
      "3           0                lhe  ...                          7                      2023\n",
      "4           0                lhe  ...                          7                      2023\n",
      "...       ...                ...  ...                        ...                       ...\n",
      "51866       0                lhe  ...                         11                      2023\n",
      "51867       0                lhe  ...                         11                      2023\n",
      "51868       0                lhe  ...                         11                      2023\n",
      "51869       0                lhe  ...                         11                      2023\n",
      "51870       0                lhe  ...                         11                      2023\n",
      "\n",
      "[51871 rows x 61 columns]\n",
      "       status departure.iataCode  ...                     airline.name departure.day_of_week\n",
      "0           0                lhe  ...                        flyjinnah                     0\n",
      "1           0                lhe  ...  pakistan international airlines                     3\n",
      "2           0                lhe  ...               ethiopian airlines                     3\n",
      "3           2                lhe  ...                          airblue                     4\n",
      "4           0                lhe  ...                              klm                     2\n",
      "...       ...                ...  ...                              ...                   ...\n",
      "14977       0                lhe  ...                          airblue                     3\n",
      "14978       0                lhe  ...  pakistan international airlines                     5\n",
      "14979       0                lhe  ...                  british airways                     5\n",
      "14980       0                lhe  ...                         oman air                     0\n",
      "14981       0                lhe  ...                        mahan air                     6\n",
      "\n",
      "[14982 rows x 47 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51871 entries, 0 to 51870\n",
      "Data columns (total 61 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   status                             51871 non-null  int64         \n",
      " 1   departure.iataCode                 51871 non-null  object        \n",
      " 2   departure.icaoCode                 51871 non-null  object        \n",
      " 3   departure.terminal                 51871 non-null  object        \n",
      " 4   departure.scheduledTime            51871 non-null  object        \n",
      " 5   departure.estimatedTime            51871 non-null  datetime64[ns]\n",
      " 6   departure.actualTime               51871 non-null  datetime64[ns]\n",
      " 7   departure.estimatedRunway          51871 non-null  object        \n",
      " 8   departure.actualRunway             51871 non-null  object        \n",
      " 9   arrival.scheduledTime              51871 non-null  object        \n",
      " 10  arrival.estimatedTime              51871 non-null  object        \n",
      " 11  airline.iataCode                   51871 non-null  object        \n",
      " 12  airline.icaoCode                   51871 non-null  object        \n",
      " 13  flight.number                      51871 non-null  int64         \n",
      " 14  flight.iataNumber                  51871 non-null  object        \n",
      " 15  flight.icaoNumber                  51871 non-null  object        \n",
      " 16  arrival.actualTime                 51871 non-null  object        \n",
      " 17  arrival.estimatedRunway            50843 non-null  object        \n",
      " 18  arrival.actualRunway               51871 non-null  object        \n",
      " 19  departure.delay_minutes            51871 non-null  float64       \n",
      " 20  departure.hour_of_day              51871 non-null  int64         \n",
      " 21  departure.month                    51871 non-null  int64         \n",
      " 22  status_encoded                     51871 non-null  int64         \n",
      " 23  Departure_Date                     51871 non-null  object        \n",
      " 24  Departure_Month                    51871 non-null  object        \n",
      " 25  Departure_Day                      51871 non-null  int64         \n",
      " 26  Departure_Hour                     51871 non-null  int64         \n",
      " 27  Month                              51871 non-null  object        \n",
      " 28  Day                                51871 non-null  float64       \n",
      " 29  Temperature (°F) Max               51871 non-null  float64       \n",
      " 30  Temperature (°F) Avg               51871 non-null  float64       \n",
      " 31  Temperature (°F) Min               51871 non-null  float64       \n",
      " 32  Dew Point (°F) Max                 51871 non-null  float64       \n",
      " 33  Dew Point (°F) Avg                 51871 non-null  float64       \n",
      " 34  Dew Point (°F) Min                 51871 non-null  float64       \n",
      " 35  Humidity (%) Max                   51871 non-null  float64       \n",
      " 36  Humidity (%) Avg                   51871 non-null  float64       \n",
      " 37  Humidity (%) Min                   51871 non-null  float64       \n",
      " 38  Wind Speed (mph) Max               51871 non-null  float64       \n",
      " 39  Wind Speed (mph) Avg               51871 non-null  float64       \n",
      " 40  Wind Speed (mph) Min               51871 non-null  float64       \n",
      " 41  Pressure (in) Max                  51871 non-null  float64       \n",
      " 42  Pressure (in) Avg                  51871 non-null  float64       \n",
      " 43  Pressure (in) Min                  51871 non-null  float64       \n",
      " 44  Precipitation (in) Total           51871 non-null  float64       \n",
      " 45  delay_status                       51871 non-null  object        \n",
      " 46  delay_category                     51870 non-null  object        \n",
      " 47  airline.name                       51871 non-null  object        \n",
      " 48  departure.day_of_week              51871 non-null  int64         \n",
      " 49  departure.estimatedTime_hour       51871 non-null  int32         \n",
      " 50  departure.estimatedTime_minute     51871 non-null  int32         \n",
      " 51  departure.estimatedTime_dayofweek  51871 non-null  int32         \n",
      " 52  departure.estimatedTime_day        51871 non-null  int32         \n",
      " 53  departure.estimatedTime_month      51871 non-null  int32         \n",
      " 54  departure.estimatedTime_year       51871 non-null  int32         \n",
      " 55  departure.actualTime_hour          51871 non-null  int32         \n",
      " 56  departure.actualTime_minute        51871 non-null  int32         \n",
      " 57  departure.actualTime_dayofweek     51871 non-null  int32         \n",
      " 58  departure.actualTime_day           51871 non-null  int32         \n",
      " 59  departure.actualTime_month         51871 non-null  int32         \n",
      " 60  departure.actualTime_year          51871 non-null  int32         \n",
      "dtypes: datetime64[ns](2), float64(18), int32(12), int64(8), object(21)\n",
      "memory usage: 21.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14982 entries, 0 to 14981\n",
      "Data columns (total 47 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   status                     14982 non-null  int64  \n",
      " 1   departure.iataCode         14982 non-null  object \n",
      " 2   departure.icaoCode         14982 non-null  object \n",
      " 3   departure.scheduledTime    14982 non-null  object \n",
      " 4   departure.estimatedRunway  14982 non-null  object \n",
      " 5   departure.actualRunway     14982 non-null  object \n",
      " 6   arrival.scheduledTime      14982 non-null  object \n",
      " 7   arrival.estimatedTime      14982 non-null  object \n",
      " 8   airline.iataCode           14982 non-null  object \n",
      " 9   airline.icaoCode           14982 non-null  object \n",
      " 10  flight.number              14982 non-null  int64  \n",
      " 11  flight.iataNumber          14982 non-null  object \n",
      " 12  flight.icaoNumber          14982 non-null  object \n",
      " 13  departure.terminal         14982 non-null  object \n",
      " 14  arrival.actualTime         14982 non-null  object \n",
      " 15  arrival.estimatedRunway    14837 non-null  object \n",
      " 16  arrival.actualRunway       14982 non-null  object \n",
      " 17  departure.hour_of_day      14982 non-null  int64  \n",
      " 18  departure.month            14982 non-null  int64  \n",
      " 19  status_encoded             14982 non-null  int64  \n",
      " 20  Departure_Date             14982 non-null  object \n",
      " 21  Departure_Month            14982 non-null  object \n",
      " 22  Departure_Day              14982 non-null  int64  \n",
      " 23  Month                      14982 non-null  object \n",
      " 24  Day                        14982 non-null  float64\n",
      " 25  Temperature (°F) Max       14982 non-null  float64\n",
      " 26  Temperature (°F) Avg       14982 non-null  float64\n",
      " 27  Temperature (°F) Min       14982 non-null  float64\n",
      " 28  Dew Point (°F) Max         14982 non-null  float64\n",
      " 29  Dew Point (°F) Avg         14982 non-null  float64\n",
      " 30  Dew Point (°F) Min         14982 non-null  float64\n",
      " 31  Humidity (%) Max           14982 non-null  float64\n",
      " 32  Humidity (%) Avg           14982 non-null  float64\n",
      " 33  Humidity (%) Min           14982 non-null  float64\n",
      " 34  Wind Speed (mph) Max       14982 non-null  float64\n",
      " 35  Wind Speed (mph) Avg       14982 non-null  float64\n",
      " 36  Wind Speed (mph) Min       14982 non-null  float64\n",
      " 37  Pressure (in) Max          14982 non-null  float64\n",
      " 38  Pressure (in) Avg          14982 non-null  float64\n",
      " 39  Pressure (in) Min          14982 non-null  float64\n",
      " 40  Precipitation (in) Total   14982 non-null  float64\n",
      " 41  Departure_Hour             14982 non-null  int64  \n",
      " 42  departure.delay_minutes    14982 non-null  float64\n",
      " 43  delay_status               14982 non-null  object \n",
      " 44  delay_category             14982 non-null  object \n",
      " 45  airline.name               14982 non-null  object \n",
      " 46  departure.day_of_week      14982 non-null  int64  \n",
      "dtypes: float64(18), int64(8), object(21)\n",
      "memory usage: 5.4+ MB\n",
      "None\n",
      "status                            0\n",
      "departure.iataCode                0\n",
      "departure.icaoCode                0\n",
      "departure.terminal                0\n",
      "departure.scheduledTime           0\n",
      "                                 ..\n",
      "departure.actualTime_minute       0\n",
      "departure.actualTime_dayofweek    0\n",
      "departure.actualTime_day          0\n",
      "departure.actualTime_month        0\n",
      "departure.actualTime_year         0\n",
      "Length: 61, dtype: int64\n",
      "status                         0\n",
      "departure.iataCode             0\n",
      "departure.icaoCode             0\n",
      "departure.scheduledTime        0\n",
      "departure.estimatedRunway      0\n",
      "departure.actualRunway         0\n",
      "arrival.scheduledTime          0\n",
      "arrival.estimatedTime          0\n",
      "airline.iataCode               0\n",
      "airline.icaoCode               0\n",
      "flight.number                  0\n",
      "flight.iataNumber              0\n",
      "flight.icaoNumber              0\n",
      "departure.terminal             0\n",
      "arrival.actualTime             0\n",
      "arrival.estimatedRunway      145\n",
      "arrival.actualRunway           0\n",
      "departure.hour_of_day          0\n",
      "departure.month                0\n",
      "status_encoded                 0\n",
      "Departure_Date                 0\n",
      "Departure_Month                0\n",
      "Departure_Day                  0\n",
      "Month                          0\n",
      "Day                            0\n",
      "Temperature (°F) Max           0\n",
      "Temperature (°F) Avg           0\n",
      "Temperature (°F) Min           0\n",
      "Dew Point (°F) Max             0\n",
      "Dew Point (°F) Avg             0\n",
      "Dew Point (°F) Min             0\n",
      "Humidity (%) Max               0\n",
      "Humidity (%) Avg               0\n",
      "Humidity (%) Min               0\n",
      "Wind Speed (mph) Max           0\n",
      "Wind Speed (mph) Avg           0\n",
      "Wind Speed (mph) Min           0\n",
      "Pressure (in) Max              0\n",
      "Pressure (in) Avg              0\n",
      "Pressure (in) Min              0\n",
      "Precipitation (in) Total       0\n",
      "Departure_Hour                 0\n",
      "departure.delay_minutes        0\n",
      "delay_status                   0\n",
      "delay_category                 0\n",
      "airline.name                   0\n",
      "departure.day_of_week          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Load datasets (train and test data)\n",
    "train_df = pd.read_csv('merged_features_drop_cleaned_train_data.csv')\n",
    "test_df = pd.read_csv('merged_features_drop_cleaned_test_data.csv')\n",
    "\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "print(train_df.info())\n",
    "print(test_df.info())\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfde5180-f3d8-4e3b-bb77-ba0a4a407592",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('merged_features_drop_cleaned_train_data.csv')\n",
    "test_df=pd.read_csv('merged_features_drop_cleaned_test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e0b221-aea0-46b2-8a0f-db5283bf18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b9ef2-2f33-437c-9852-693148c1cbb2",
   "metadata": {},
   "source": [
    "\n",
    "##############################################\n",
    "# PHASE 3: Analytical and Predictive Tasks\n",
    "##############################################\n",
    "\n",
    "# Load your train and test datasets\n",
    "# train_df and test_df should be preprocessed (handle missing values, convert datetimes, feature engineering, etc.)\n",
    "# Ensure that columns in test_df are in the same format as train_df.\n",
    "# Assume that 'departure.delay_minutes' is present in train_df and needs to be predicted or classified.\n",
    "#train_df = pd.read_csv(\"train.csv\")\n",
    "#test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4620d6-7fc5-4ea7-8b77-98fe575490fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example feature selection (adjust according to your dataset)\n",
    "# Let's assume we've already chosen a set of relevant numerical and categorical features.\n",
    "numeric_features = ['Temperature (°F) Avg', 'Humidity (%) Avg', 'Wind Speed (mph) Avg', 'Pressure (in) Avg']\n",
    "categorical_features = ['departure.iataCode', 'departure.icaoCode', 'airline.iataCode']\n",
    "\n",
    "# Common preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b181e36-f8a6-4f21-8072-2bc9c177c8d2",
   "metadata": {},
   "source": [
    "### 1. Binary Classification ###\n",
    "# Binary Criteria:\n",
    "# delay = 0 -> on-time\n",
    "# delay > 0 -> delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47ce072-3c4c-48d7-99c1-bce819376f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_df['binary_target'] = train_df['departure.delay_minutes'].apply(lambda x: 'on-time' if x == 0 else 'delayed')\n",
    "X_bin = train_df[numeric_features + categorical_features]\n",
    "y_bin = train_df['binary_target']\n",
    "\n",
    "X_train_bin, X_val_bin, y_train_bin, y_val_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n",
    "\n",
    "binary_clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "binary_clf_pipeline.fit(X_train_bin, y_train_bin)\n",
    "y_pred_bin = binary_clf_pipeline.predict(X_val_bin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e63925-49ac-47ac-9051-4ffa3ca3facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Metrics:\n",
      "Accuracy: 0.7332048192771085\n",
      "Precision: 0.7873000716161375\n",
      "Recall: 0.8699551569506726\n",
      "F1-Score: 0.8265664160401003\n",
      "Confusion Matrix:\n",
      " [[1011 1782]\n",
      " [ 986 6596]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     delayed       0.79      0.87      0.83      7582\n",
      "     on-time       0.51      0.36      0.42      2793\n",
      "\n",
      "    accuracy                           0.73     10375\n",
      "   macro avg       0.65      0.62      0.62     10375\n",
      "weighted avg       0.71      0.73      0.72     10375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for Binary Classification\n",
    "acc = accuracy_score(y_val_bin, y_pred_bin)\n",
    "prec = precision_score(y_val_bin, y_pred_bin, pos_label='delayed')\n",
    "rec = recall_score(y_val_bin, y_pred_bin, pos_label='delayed')\n",
    "f1 = f1_score(y_val_bin, y_pred_bin, pos_label='delayed')\n",
    "cm = confusion_matrix(y_val_bin, y_pred_bin, labels=['on-time', 'delayed'])\n",
    "\n",
    "print(\"Binary Classification Metrics:\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_bin, y_pred_bin))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b186798-3853-442a-98f6-af00fdbda175",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ee021241-20fa-4d04-b8e5-5b6112b5abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Binary Classification Metrics:\n",
      "Accuracy: 0.7661686746987951\n",
      "Precision: 0.781072830353249\n",
      "Recall: 0.9448694275916645\n",
      "F1-Score: 0.8551987585054315\n",
      "Confusion Matrix:\n",
      " [[ 785 2008]\n",
      " [ 418 7164]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.28      0.39      2793\n",
      "           1       0.78      0.94      0.86      7582\n",
      "\n",
      "    accuracy                           0.77     10375\n",
      "   macro avg       0.72      0.61      0.62     10375\n",
      "weighted avg       0.75      0.77      0.73     10375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Assuming 'train_df', 'numeric_features', and 'categorical_features' are already defined\n",
    "\n",
    "# Convert the 'binary_target' to numeric (0: 'on-time', 1: 'delayed')\n",
    "train_df['binary_target'] = train_df['departure.delay_minutes'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Define the features and target\n",
    "X_bin = train_df[numeric_features + categorical_features]\n",
    "y_bin = train_df['binary_target']\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train_bin, X_val_bin, y_train_bin, y_val_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n",
    "\n",
    "# Define the preprocessing for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Scale numeric features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Impute missing values with a placeholder\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine the transformations using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the pipeline with XGBClassifier\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "xgb_pipeline.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bin = xgb_pipeline.predict(X_val_bin)\n",
    "\n",
    "# Evaluate the model\n",
    "acc = accuracy_score(y_val_bin, y_pred_bin)\n",
    "prec = precision_score(y_val_bin, y_pred_bin)\n",
    "rec = recall_score(y_val_bin, y_pred_bin)\n",
    "f1 = f1_score(y_val_bin, y_pred_bin)\n",
    "cm = confusion_matrix(y_val_bin, y_pred_bin)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"XGBoost Binary Classification Metrics:\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_bin, y_pred_bin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "04ea7ed8-ec36-4cfe-a80e-5121e68e8ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>departure.iataCode</th>\n",
       "      <th>departure.icaoCode</th>\n",
       "      <th>departure.terminal</th>\n",
       "      <th>departure.scheduledTime</th>\n",
       "      <th>departure.estimatedTime</th>\n",
       "      <th>departure.actualTime</th>\n",
       "      <th>departure.estimatedRunway</th>\n",
       "      <th>departure.actualRunway</th>\n",
       "      <th>arrival.scheduledTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure (in) Max</th>\n",
       "      <th>Pressure (in) Avg</th>\n",
       "      <th>Pressure (in) Min</th>\n",
       "      <th>Precipitation (in) Total</th>\n",
       "      <th>delay_status</th>\n",
       "      <th>delay_category</th>\n",
       "      <th>airline.name</th>\n",
       "      <th>departure.day_of_week</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>multi_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-20 20:50:00</td>\n",
       "      <td>2023-07-20 20:00:00</td>\n",
       "      <td>2023-07-20 20:15:00</td>\n",
       "      <td>2023-07-20 20:15:00</td>\n",
       "      <td>2023-07-20 20:15:00</td>\n",
       "      <td>2023-07-20 23:20:00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saudia</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Short Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-07-18 15:05:00</td>\n",
       "      <td>2023-07-18 15:05:00</td>\n",
       "      <td>2023-07-18 15:05:00</td>\n",
       "      <td>2023-07-20 20:15:00</td>\n",
       "      <td>2023-07-18 15:05:00</td>\n",
       "      <td>2023-07-18 16:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>on-time</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>flyjinnah</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-07-23 09:50:00</td>\n",
       "      <td>2023-07-18 15:05:00</td>\n",
       "      <td>2023-07-23 09:50:00</td>\n",
       "      <td>2023-07-20 20:15:00</td>\n",
       "      <td>2023-07-23 09:50:00</td>\n",
       "      <td>2023-07-23 11:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>on-time</td>\n",
       "      <td>No Delay</td>\n",
       "      <td>flyjinnah</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-26 23:30:00</td>\n",
       "      <td>2023-07-26 23:30:00</td>\n",
       "      <td>2023-07-26 23:51:00</td>\n",
       "      <td>2023-07-26 23:51:00</td>\n",
       "      <td>2023-07-26 23:51:00</td>\n",
       "      <td>2023-07-27 01:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Short Delay</td>\n",
       "      <td>pakistan international airlines</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Short Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-07-20 11:35:00</td>\n",
       "      <td>2023-07-20 17:15:00</td>\n",
       "      <td>2023-07-20 17:15:00</td>\n",
       "      <td>2023-07-26 23:51:00</td>\n",
       "      <td>2023-07-20 11:35:00</td>\n",
       "      <td>2023-07-20 14:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Long Delay</td>\n",
       "      <td>serene air</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Long Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-11-16 09:50:00</td>\n",
       "      <td>2023-11-16 09:50:00</td>\n",
       "      <td>2023-11-16 10:03:00</td>\n",
       "      <td>2023-11-16 10:03:00</td>\n",
       "      <td>2023-11-16 10:03:00</td>\n",
       "      <td>2023-11-16 11:45:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Short Delay</td>\n",
       "      <td>flyjinnah</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Short Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-16 11:40:00</td>\n",
       "      <td>2023-11-16 11:40:00</td>\n",
       "      <td>2023-11-16 11:48:00</td>\n",
       "      <td>2023-11-16 11:48:00</td>\n",
       "      <td>2023-11-16 11:48:00</td>\n",
       "      <td>2023-11-16 15:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Short Delay</td>\n",
       "      <td>saudia</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Short Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51868</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-27 10:50:00</td>\n",
       "      <td>2023-11-27 14:35:00</td>\n",
       "      <td>2023-11-27 14:35:00</td>\n",
       "      <td>2023-11-16 11:48:00</td>\n",
       "      <td>2023-11-27 10:50:00</td>\n",
       "      <td>2023-11-27 13:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Long Delay</td>\n",
       "      <td>pakistan international airlines</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Long Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51869</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-19 02:00:00</td>\n",
       "      <td>2023-11-19 11:00:00</td>\n",
       "      <td>2023-11-19 11:00:00</td>\n",
       "      <td>2023-11-16 11:48:00</td>\n",
       "      <td>2023-11-19 02:00:00</td>\n",
       "      <td>2023-11-19 10:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Long Delay</td>\n",
       "      <td>pakistan international airlines</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Long Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51870</th>\n",
       "      <td>0</td>\n",
       "      <td>lhe</td>\n",
       "      <td>opla</td>\n",
       "      <td>m</td>\n",
       "      <td>2023-11-23 06:30:00</td>\n",
       "      <td>2023-11-23 06:30:00</td>\n",
       "      <td>2023-11-23 06:47:00</td>\n",
       "      <td>2023-11-23 06:47:00</td>\n",
       "      <td>2023-11-23 06:47:00</td>\n",
       "      <td>2023-11-23 10:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.2</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed</td>\n",
       "      <td>Short Delay</td>\n",
       "      <td>pakistan international airlines</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Short Delay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51871 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status departure.iataCode departure.icaoCode departure.terminal  \\\n",
       "0           0                lhe               opla                  m   \n",
       "1           0                lhe               opla            Unknown   \n",
       "2           0                lhe               opla            Unknown   \n",
       "3           0                lhe               opla                  m   \n",
       "4           0                lhe               opla                  m   \n",
       "...       ...                ...                ...                ...   \n",
       "51866       0                lhe               opla            Unknown   \n",
       "51867       0                lhe               opla                  m   \n",
       "51868       0                lhe               opla                  m   \n",
       "51869       0                lhe               opla                  m   \n",
       "51870       0                lhe               opla                  m   \n",
       "\n",
       "      departure.scheduledTime departure.estimatedTime departure.actualTime  \\\n",
       "0         2023-07-20 20:50:00     2023-07-20 20:00:00  2023-07-20 20:15:00   \n",
       "1         2023-07-18 15:05:00     2023-07-18 15:05:00  2023-07-18 15:05:00   \n",
       "2         2023-07-23 09:50:00     2023-07-18 15:05:00  2023-07-23 09:50:00   \n",
       "3         2023-07-26 23:30:00     2023-07-26 23:30:00  2023-07-26 23:51:00   \n",
       "4         2023-07-20 11:35:00     2023-07-20 17:15:00  2023-07-20 17:15:00   \n",
       "...                       ...                     ...                  ...   \n",
       "51866     2023-11-16 09:50:00     2023-11-16 09:50:00  2023-11-16 10:03:00   \n",
       "51867     2023-11-16 11:40:00     2023-11-16 11:40:00  2023-11-16 11:48:00   \n",
       "51868     2023-11-27 10:50:00     2023-11-27 14:35:00  2023-11-27 14:35:00   \n",
       "51869     2023-11-19 02:00:00     2023-11-19 11:00:00  2023-11-19 11:00:00   \n",
       "51870     2023-11-23 06:30:00     2023-11-23 06:30:00  2023-11-23 06:47:00   \n",
       "\n",
       "      departure.estimatedRunway departure.actualRunway arrival.scheduledTime  \\\n",
       "0           2023-07-20 20:15:00    2023-07-20 20:15:00   2023-07-20 23:20:00   \n",
       "1           2023-07-20 20:15:00    2023-07-18 15:05:00   2023-07-18 16:50:00   \n",
       "2           2023-07-20 20:15:00    2023-07-23 09:50:00   2023-07-23 11:35:00   \n",
       "3           2023-07-26 23:51:00    2023-07-26 23:51:00   2023-07-27 01:30:00   \n",
       "4           2023-07-26 23:51:00    2023-07-20 11:35:00   2023-07-20 14:00:00   \n",
       "...                         ...                    ...                   ...   \n",
       "51866       2023-11-16 10:03:00    2023-11-16 10:03:00   2023-11-16 11:45:00   \n",
       "51867       2023-11-16 11:48:00    2023-11-16 11:48:00   2023-11-16 15:25:00   \n",
       "51868       2023-11-16 11:48:00    2023-11-27 10:50:00   2023-11-27 13:30:00   \n",
       "51869       2023-11-16 11:48:00    2023-11-19 02:00:00   2023-11-19 10:30:00   \n",
       "51870       2023-11-23 06:47:00    2023-11-23 06:47:00   2023-11-23 10:10:00   \n",
       "\n",
       "       ... Pressure (in) Max Pressure (in) Avg Pressure (in) Min  \\\n",
       "0      ...              28.9              28.8              28.7   \n",
       "1      ...              28.8              28.8              28.7   \n",
       "2      ...              29.0              28.9              28.8   \n",
       "3      ...              28.9              28.9              28.8   \n",
       "4      ...              28.9              28.8              28.7   \n",
       "...    ...               ...               ...               ...   \n",
       "51866  ...              29.4              29.3              29.3   \n",
       "51867  ...              29.4              29.3              29.3   \n",
       "51868  ...              29.3              29.3              29.2   \n",
       "51869  ...              29.4              28.7               0.0   \n",
       "51870  ...              29.2              28.6               0.0   \n",
       "\n",
       "       Precipitation (in) Total delay_status delay_category  \\\n",
       "0                           0.0      delayed            NaN   \n",
       "1                           0.0      on-time       No Delay   \n",
       "2                           0.0      on-time       No Delay   \n",
       "3                           0.0      delayed    Short Delay   \n",
       "4                           0.0      delayed     Long Delay   \n",
       "...                         ...          ...            ...   \n",
       "51866                       0.0      delayed    Short Delay   \n",
       "51867                       0.0      delayed    Short Delay   \n",
       "51868                       0.0      delayed     Long Delay   \n",
       "51869                       0.0      delayed     Long Delay   \n",
       "51870                       0.0      delayed    Short Delay   \n",
       "\n",
       "                          airline.name departure.day_of_week binary_target  \\\n",
       "0                               saudia                     3             1   \n",
       "1                            flyjinnah                     1             0   \n",
       "2                            flyjinnah                     6             0   \n",
       "3      pakistan international airlines                     2             1   \n",
       "4                           serene air                     3             1   \n",
       "...                                ...                   ...           ...   \n",
       "51866                        flyjinnah                     3             1   \n",
       "51867                           saudia                     3             1   \n",
       "51868  pakistan international airlines                     0             1   \n",
       "51869  pakistan international airlines                     6             1   \n",
       "51870  pakistan international airlines                     3             1   \n",
       "\n",
       "       multi_target  \n",
       "0       Short Delay  \n",
       "1          No Delay  \n",
       "2          No Delay  \n",
       "3       Short Delay  \n",
       "4        Long Delay  \n",
       "...             ...  \n",
       "51866   Short Delay  \n",
       "51867   Short Delay  \n",
       "51868    Long Delay  \n",
       "51869    Long Delay  \n",
       "51870   Short Delay  \n",
       "\n",
       "[51871 rows x 51 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e446f-f5a9-4378-bead-104941886a03",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Multi-Class Classification ###\n",
    "# Categories:\n",
    "# No Delay (0)\n",
    "# Short Delay (<45)\n",
    "# Moderate Delay (45–175)\n",
    "# Long Delay (>175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00629d0-32bd-47c1-a8dd-ff594ad5a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def categorize_delay(x):\n",
    "    if x == 0:\n",
    "        return 'No Delay'\n",
    "    elif x < 45:\n",
    "        return 'Short Delay'\n",
    "    elif 45 <= x <= 175:\n",
    "        return 'Moderate Delay'\n",
    "    else:\n",
    "        return 'Long Delay'\n",
    "\n",
    "train_df['multi_target'] = train_df['departure.delay_minutes'].apply(categorize_delay)\n",
    "X_multi = train_df[numeric_features + categorical_features]\n",
    "y_multi = train_df['multi_target']\n",
    "\n",
    "X_train_multi, X_val_multi, y_train_multi, y_val_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi)\n",
    "\n",
    "multi_clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5367419a-6ab4-4da3-8307-0b099d9691df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification Accuracy: 0.6466506024096386\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Long Delay       0.06      0.03      0.04       229\n",
      "Moderate Delay       0.15      0.05      0.08       625\n",
      "      No Delay       0.47      0.40      0.43      2793\n",
      "   Short Delay       0.72      0.82      0.77      6728\n",
      "\n",
      "      accuracy                           0.65     10375\n",
      "     macro avg       0.35      0.33      0.33     10375\n",
      "  weighted avg       0.61      0.65      0.62     10375\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   6   13   83  127]\n",
      " [  11   33  166  415]\n",
      " [  34   58 1120 1581]\n",
      " [  43  121 1014 5550]]\n",
      "Regression Metrics:\n",
      "MAE: 27.49247157812209\n",
      "RMSE: 68.74128282085401\n"
     ]
    }
   ],
   "source": [
    "multi_clf_pipeline.fit(X_train_multi, y_train_multi)\n",
    "y_pred_multi = multi_clf_pipeline.predict(X_val_multi)\n",
    "\n",
    "# Evaluation for Multi-Class Classification\n",
    "acc_multi = accuracy_score(y_val_multi, y_pred_multi)\n",
    "print(\"Multi-Class Classification Accuracy:\", acc_multi)\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_multi, y_pred_multi))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_multi, y_pred_multi))\n",
    "\n",
    "### 3. Regression Analysis ###\n",
    "# Predict exact delay duration\n",
    "X_reg = train_df[numeric_features + categorical_features]\n",
    "y_reg = train_df['departure.delay_minutes']\n",
    "\n",
    "X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "reg_pipeline.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = reg_pipeline.predict(X_val_reg)\n",
    "\n",
    "# Evaluation for Regression\n",
    "mae = mean_absolute_error(y_val_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_reg, y_pred_reg))\n",
    "\n",
    "print(\"Regression Metrics:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b63eb-256e-4502-a597-69ecf381ef0e",
   "metadata": {},
   "source": [
    "\n",
    "##############################################\n",
    "# PHASE 4: Model Optimization and Evaluation\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24bb84-8a9a-4dea-a501-4578d2990c21",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using GridSearch for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe25419-53fb-46f9-ab26-dd8aaea761ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Params for Binary Classification: {'classifier__max_depth': None, 'classifier__n_estimators': 100}\n",
      "Regression CV RMSE: 70.64445365969823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##############################################\n",
    "# PHASE 4: Model Optimization and Evaluation\n",
    "##############################################\n",
    "\n",
    "# Example Hyperparameter Tuning using GridSearch for binary classification\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search_bin = GridSearchCV(binary_clf_pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search_bin.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "print(\"Best Params for Binary Classification:\", grid_search_bin.best_params_)\n",
    "\n",
    "best_binary_model = grid_search_bin.best_estimator_\n",
    "\n",
    "# Apply K-Fold Cross-Validation for regression\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_reg = cross_val_score(reg_pipeline, X_reg, y_reg, cv=kf, scoring='neg_mean_squared_error')\n",
    "print(\"Regression CV RMSE:\", np.sqrt(-cv_scores_reg).mean())\n",
    "\n",
    "# You can repeat similar steps for multi-class classification or other models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba635e1-6924-4931-bf5a-4de4abc0989e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19a4df-29d6-4141-a377-aa7f5de8fc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d7e533f6-d3f8-4223-a7c0-e960b8b99003",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['binary_target'] = test_df['departure.delay_minutes'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab2949-eb4e-45ca-bf49-b5d6f5a3c567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5d5c4-0086-40c3-acf4-ec81bbbc417d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006501a5-0a3e-43ca-8159-8f2e2200b779",
   "metadata": {},
   "source": [
    "#  Define the parameter grid for multi-class classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba06a737-616b-40f7-a345-8c9d3f2072c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Params for Multi-Class Classification: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for multi-class classification\n",
    "param_grid_multi = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for multi-class classification\n",
    "grid_search_multi = GridSearchCV(\n",
    "    multi_clf_pipeline,  # Your existing pipeline for multi-class\n",
    "    param_grid_multi,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',  # Use 'f1_macro' for multi-class\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Params for Multi-Class Classification:\", grid_search_multi.best_params_)\n",
    "\n",
    "# Extract the best estimator\n",
    "best_multi_model = grid_search_multi.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0de083-5732-4136-bc73-8dc2847d6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification CV F1 Scores: [0.23999497 0.26658131 0.2450343  0.16141845 0.2504014 ]\n",
      "Mean CV F1 Score: 0.23268608749922456\n",
      "Standard Deviation of CV F1 Scores: 0.03673606595780098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation with the best multi-class model\n",
    "cv_scores_multi = cross_val_score(\n",
    "    best_multi_model,\n",
    "    X_multi,\n",
    "    y_multi,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calculate and print the mean and standard deviation of F1 scores\n",
    "print(\"Multi-Class Classification CV F1 Scores:\", cv_scores_multi)\n",
    "print(\"Mean CV F1 Score:\", cv_scores_multi.mean())\n",
    "print(\"Standard Deviation of CV F1 Scores:\", cv_scores_multi.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee9c35-32a5-44ed-bdc6-bed4305223c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define a new pipeline for SVM\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42, probability=True))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    param_grid_svm,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_svm.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Params for SVM Multi-Class Classification:\", grid_search_svm.best_params_)\n",
    "\n",
    "# Extract the best estimator\n",
    "best_svm_multi = grid_search_svm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee66243-364c-4dcf-ae1f-0920917d440a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "049fbeca-dcad-4029-b91b-f5c50db21470",
   "metadata": {},
   "source": [
    "# Define a new pipeline for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64201282-1679-47d1-808f-1320f4d4669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Params for Gradient Boosting Multi-Class Classification: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 7, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define a new pipeline for Gradient Boosting\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for Gradient Boosting\n",
    "grid_search_gb = GridSearchCV(\n",
    "    gb_pipeline,\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_gb.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Params for Gradient Boosting Multi-Class Classification:\", grid_search_gb.best_params_)\n",
    "\n",
    "# Extract the best estimator\n",
    "best_gb_multi = grid_search_gb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274bf25-1b9b-4710-8344-ef3541327d2e",
   "metadata": {},
   "source": [
    "# cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db55ccf-2a26-458a-ad7d-cd166c6e7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_svm_multi = cross_val_score(\n",
    "    best_svm_multi,\n",
    "    X_multi,\n",
    "    y_multi,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"SVM Multi-Class Classification CV F1 Scores:\", cv_scores_svm_multi)\n",
    "print(\"Mean CV F1 Score:\", cv_scores_svm_multi.mean())\n",
    "print(\"Standard Deviation of CV F1 Scores:\", cv_scores_svm_multi.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f19a99f1-4b66-45a8-bac5-8b3a52fbbaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Multi-Class Classification CV F1 Scores: [0.27256008 0.28049962 0.23911537 0.17843221 0.27039693]\n",
      "Mean CV F1 Score: 0.24820084413144236\n",
      "Standard Deviation of CV F1 Scores: 0.037628334362432826\n"
     ]
    }
   ],
   "source": [
    "cv_scores_gb_multi = cross_val_score(\n",
    "    best_gb_multi,\n",
    "    X_multi,\n",
    "    y_multi,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Gradient Boosting Multi-Class Classification CV F1 Scores:\", cv_scores_gb_multi)\n",
    "print(\"Mean CV F1 Score:\", cv_scores_gb_multi.mean())\n",
    "print(\"Standard Deviation of CV F1 Scores:\", cv_scores_gb_multi.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "712049d2-9605-40c0-be83-079a3b70f302",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dictionary to store model performances\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_performance \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search_multi\u001b[38;5;241m.\u001b[39mbest_score_,\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search_svm\u001b[38;5;241m.\u001b[39mbest_score_,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradientBoosting\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search_gb\u001b[38;5;241m.\u001b[39mbest_score_\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display model performances\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, score \u001b[38;5;129;01min\u001b[39;00m model_performance\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search_svm' is not defined"
     ]
    }
   ],
   "source": [
    "# Dictionary to store model performances\n",
    "model_performance = {\n",
    "    'RandomForest': grid_search_multi.best_score_,\n",
    "    'SVM': grid_search_svm.best_score_,\n",
    "    'GradientBoosting': grid_search_gb.best_score_\n",
    "}\n",
    "\n",
    "# Display model performances\n",
    "for model_name, score in model_performance.items():\n",
    "    print(f\"{model_name} Multi-Class F1 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1269e0de-03a2-497c-8182-42ae643d850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Multi-Class F1 Score: 0.3408\n",
      "GradientBoosting Multi-Class F1 Score: 0.3456\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store model performances\n",
    "model_performance = {\n",
    "    'RandomForest': grid_search_multi.best_score_,\n",
    "    'GradientBoosting': grid_search_gb.best_score_\n",
    "}\n",
    "\n",
    "# Display model performances\n",
    "for model_name, score in model_performance.items():\n",
    "    print(f\"{model_name} Multi-Class F1 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06b538-6c4b-45d2-aff8-039d96f4ded0",
   "metadata": {},
   "source": [
    "# Define a new pipeline for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "456d6f7a-59d4-41f4-8a71-f07aeeddf845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Params for KNN Multi-Class Classification: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 5, 'classifier__weights': 'uniform'}\n",
      "KNN Multi-Class Classification CV F1 Scores: [0.26125886 0.29312501 0.28596028 0.21052747 0.28140239]\n",
      "Mean CV F1 Score: 0.2664548044433126\n",
      "Standard Deviation of CV F1 Scores: 0.029900029432135426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define a new pipeline for KNN\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'classifier__n_neighbors': [5, 10, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for KNN\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn_pipeline,\n",
    "    param_grid_knn,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_knn.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Params for KNN Multi-Class Classification:\", grid_search_knn.best_params_)\n",
    "\n",
    "# Extract the best estimator\n",
    "best_knn_multi = grid_search_knn.best_estimator_\n",
    "\n",
    "# Cross-Validation for KNN\n",
    "cv_scores_knn_multi = cross_val_score(\n",
    "    best_knn_multi,\n",
    "    X_multi,\n",
    "    y_multi,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"KNN Multi-Class Classification CV F1 Scores:\", cv_scores_knn_multi)\n",
    "print(\"Mean CV F1 Score:\", cv_scores_knn_multi.mean())\n",
    "print(\"Standard Deviation of CV F1 Scores:\", cv_scores_knn_multi.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712b554-d883-4372-8a4d-dc8cfb7e05b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402ae3a-7239-42d1-977c-755accab2f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed71609-b5b7-4697-aacb-383e4bf4f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example selection based on highest F1 Score\n",
    "best_binary_model = grid_search_bin.best_estimator_\n",
    "best_multi_model = grid_search_gb.best_estimator_  # Assuming Gradient Boosting performed best\n",
    "\n",
    "# Optionally, you can keep multiple models for ensemble methods or further experimentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e456aca-6bd0-4c99-90b9-942a11acd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example selection based on highest F1 Score\n",
    "best_binary_model = grid_search_bin.best_estimator_\n",
    "best_multi_model = grid_search_gb.best_estimator_  # Assuming Gradient Boosting performed best\n",
    "\n",
    "# Optionally, keep other best models for ensemble methods or further experimentation\n",
    "#best_svm_multi = grid_search_svm.best_estimator_\n",
    "best_knn_multi = grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c9b6a-9279-4f32-86f2-06e6ac92e04a",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Phase 5: Model Testing and Submission\n",
    "# ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e95ee2f2-0069-46ec-bb09-0259714bac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14982 entries, 0 to 14981\n",
      "Data columns (total 57 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   status                     14982 non-null  int64  \n",
      " 1   departure.iataCode         14982 non-null  object \n",
      " 2   departure.icaoCode         14982 non-null  object \n",
      " 3   departure.scheduledTime    14982 non-null  object \n",
      " 4   departure.estimatedRunway  8730 non-null   object \n",
      " 5   departure.actualRunway     14982 non-null  object \n",
      " 6   arrival.scheduledTime      14982 non-null  object \n",
      " 7   arrival.estimatedTime      8429 non-null   object \n",
      " 8   airline.iataCode           14976 non-null  object \n",
      " 9   airline.icaoCode           14981 non-null  object \n",
      " 10  flight.number              14982 non-null  int64  \n",
      " 11  flight.iataNumber          14976 non-null  object \n",
      " 12  flight.icaoNumber          14981 non-null  object \n",
      " 13  departure.terminal         14982 non-null  object \n",
      " 14  arrival.actualTime         14982 non-null  object \n",
      " 15  arrival.estimatedRunway    75 non-null     object \n",
      " 16  arrival.actualRunway       14982 non-null  object \n",
      " 17  departure.hour_of_day      14982 non-null  int64  \n",
      " 18  departure.month            14982 non-null  int64  \n",
      " 19  status_encoded             14982 non-null  int64  \n",
      " 20  Departure_Date             14982 non-null  object \n",
      " 21  Departure_Month            14982 non-null  object \n",
      " 22  Departure_Day              14982 non-null  int64  \n",
      " 23  Month                      10360 non-null  object \n",
      " 24  Day                        10360 non-null  float64\n",
      " 25  Temperature (°F) Max       14982 non-null  float64\n",
      " 26  Temperature (°F) Avg       14982 non-null  float64\n",
      " 27  Temperature (°F) Min       14982 non-null  float64\n",
      " 28  Dew Point (°F) Max         14982 non-null  float64\n",
      " 29  Dew Point (°F) Avg         14982 non-null  float64\n",
      " 30  Dew Point (°F) Min         14982 non-null  float64\n",
      " 31  Humidity (%) Max           14982 non-null  float64\n",
      " 32  Humidity (%) Avg           14982 non-null  float64\n",
      " 33  Humidity (%) Min           14982 non-null  float64\n",
      " 34  Wind Speed (mph) Max       14982 non-null  float64\n",
      " 35  Wind Speed (mph) Avg       14982 non-null  float64\n",
      " 36  Wind Speed (mph) Min       14982 non-null  float64\n",
      " 37  Pressure (in) Max          14982 non-null  float64\n",
      " 38  Pressure (in) Avg          14982 non-null  float64\n",
      " 39  Pressure (in) Min          14982 non-null  float64\n",
      " 40  Precipitation (in) Total   14982 non-null  float64\n",
      " 41  Departure_Hour             14982 non-null  int64  \n",
      " 42  departure.delay_minutes    14982 non-null  float64\n",
      " 43  delay_status               14982 non-null  object \n",
      " 44  delay_category             14922 non-null  object \n",
      " 45  airline.name               14982 non-null  object \n",
      " 46  departure.day_of_week      14982 non-null  int64  \n",
      " 47  File Name                  14982 non-null  object \n",
      " 48  Flight Number              14976 non-null  object \n",
      " 49  Type                       14982 non-null  object \n",
      " 50  Status                     14982 non-null  int64  \n",
      " 51  Departure IATA Code        14982 non-null  object \n",
      " 52  Departure ICAO Code        14982 non-null  object \n",
      " 53  Scheduled Time             14982 non-null  object \n",
      " 54  Arrival Estimated Time     8429 non-null   object \n",
      " 55  Arrival IATA Code          14982 non-null  object \n",
      " 56  Arrival ICAO Code          14982 non-null  object \n",
      "dtypes: float64(18), int64(9), object(30)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4363d-b971-4f13-a54a-3a60d6bae549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badeb6ce-71c2-47ce-b107-d71f221e5fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c108d0-6ac8-4464-b805-cce2462faf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19393d-8f67-4f89-b884-04c51e017188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49733e-8a92-4a40-ab47-60fc60324483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c744654-49ac-4ee4-b59e-870ead0282fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14982 entries, 0 to 14981\n",
      "Data columns (total 47 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   status                     14982 non-null  int64  \n",
      " 1   departure.iataCode         14982 non-null  object \n",
      " 2   departure.icaoCode         14982 non-null  object \n",
      " 3   departure.scheduledTime    14982 non-null  object \n",
      " 4   departure.estimatedRunway  8730 non-null   object \n",
      " 5   departure.actualRunway     14982 non-null  object \n",
      " 6   arrival.scheduledTime      14982 non-null  object \n",
      " 7   arrival.estimatedTime      8429 non-null   object \n",
      " 8   airline.iataCode           14976 non-null  object \n",
      " 9   airline.icaoCode           14981 non-null  object \n",
      " 10  flight.number              14982 non-null  int64  \n",
      " 11  flight.iataNumber          14976 non-null  object \n",
      " 12  flight.icaoNumber          14981 non-null  object \n",
      " 13  departure.terminal         14982 non-null  object \n",
      " 14  arrival.actualTime         14982 non-null  object \n",
      " 15  arrival.estimatedRunway    75 non-null     object \n",
      " 16  arrival.actualRunway       14982 non-null  object \n",
      " 17  departure.hour_of_day      14982 non-null  int64  \n",
      " 18  departure.month            14982 non-null  int64  \n",
      " 19  status_encoded             14982 non-null  int64  \n",
      " 20  Departure_Date             14982 non-null  object \n",
      " 21  Departure_Month            14982 non-null  object \n",
      " 22  Departure_Day              14982 non-null  int64  \n",
      " 23  Month                      10360 non-null  object \n",
      " 24  Day                        10360 non-null  float64\n",
      " 25  Temperature (°F) Max       14982 non-null  float64\n",
      " 26  Temperature (°F) Avg       14982 non-null  float64\n",
      " 27  Temperature (°F) Min       14982 non-null  float64\n",
      " 28  Dew Point (°F) Max         14982 non-null  float64\n",
      " 29  Dew Point (°F) Avg         14982 non-null  float64\n",
      " 30  Dew Point (°F) Min         14982 non-null  float64\n",
      " 31  Humidity (%) Max           14982 non-null  float64\n",
      " 32  Humidity (%) Avg           14982 non-null  float64\n",
      " 33  Humidity (%) Min           14982 non-null  float64\n",
      " 34  Wind Speed (mph) Max       14982 non-null  float64\n",
      " 35  Wind Speed (mph) Avg       14982 non-null  float64\n",
      " 36  Wind Speed (mph) Min       14982 non-null  float64\n",
      " 37  Pressure (in) Max          14982 non-null  float64\n",
      " 38  Pressure (in) Avg          14982 non-null  float64\n",
      " 39  Pressure (in) Min          14982 non-null  float64\n",
      " 40  Precipitation (in) Total   14982 non-null  float64\n",
      " 41  Departure_Hour             14982 non-null  int64  \n",
      " 42  departure.delay_minutes    14982 non-null  float64\n",
      " 43  delay_status               14982 non-null  object \n",
      " 44  delay_category             14922 non-null  object \n",
      " 45  airline.name               14982 non-null  object \n",
      " 46  departure.day_of_week      14982 non-null  int64  \n",
      "dtypes: float64(18), int64(8), object(21)\n",
      "memory usage: 5.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14982 entries, 0 to 14981\n",
      "Data columns (total 46 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   status                     14982 non-null  int64  \n",
      " 1   departure.iataCode         14982 non-null  object \n",
      " 2   departure.icaoCode         14982 non-null  object \n",
      " 3   departure.scheduledTime    14982 non-null  object \n",
      " 4   departure.estimatedRunway  8730 non-null   object \n",
      " 5   departure.actualRunway     14982 non-null  object \n",
      " 6   arrival.scheduledTime      14982 non-null  object \n",
      " 7   arrival.estimatedTime      8429 non-null   object \n",
      " 8   airline.iataCode           14976 non-null  object \n",
      " 9   airline.icaoCode           14981 non-null  object \n",
      " 10  flight.number              14982 non-null  int64  \n",
      " 11  flight.iataNumber          14976 non-null  object \n",
      " 12  flight.icaoNumber          14981 non-null  object \n",
      " 13  departure.terminal         14982 non-null  object \n",
      " 14  arrival.actualTime         14982 non-null  object \n",
      " 15  arrival.estimatedRunway    75 non-null     object \n",
      " 16  arrival.actualRunway       14982 non-null  object \n",
      " 17  departure.hour_of_day      14982 non-null  int64  \n",
      " 18  departure.month            14982 non-null  int64  \n",
      " 19  status_encoded             14982 non-null  int64  \n",
      " 20  Departure_Date             14982 non-null  object \n",
      " 21  Departure_Month            14982 non-null  object \n",
      " 22  Departure_Day              14982 non-null  int64  \n",
      " 23  Month                      10360 non-null  object \n",
      " 24  Day                        10360 non-null  float64\n",
      " 25  Temperature (°F) Max       14982 non-null  float64\n",
      " 26  Temperature (°F) Avg       14982 non-null  float64\n",
      " 27  Temperature (°F) Min       14982 non-null  float64\n",
      " 28  Dew Point (°F) Max         14982 non-null  float64\n",
      " 29  Dew Point (°F) Avg         14982 non-null  float64\n",
      " 30  Dew Point (°F) Min         14982 non-null  float64\n",
      " 31  Humidity (%) Max           14982 non-null  float64\n",
      " 32  Humidity (%) Avg           14982 non-null  float64\n",
      " 33  Humidity (%) Min           14982 non-null  float64\n",
      " 34  Wind Speed (mph) Max       14982 non-null  float64\n",
      " 35  Wind Speed (mph) Avg       14982 non-null  float64\n",
      " 36  Wind Speed (mph) Min       14982 non-null  float64\n",
      " 37  Pressure (in) Max          14982 non-null  float64\n",
      " 38  Pressure (in) Avg          14982 non-null  float64\n",
      " 39  Pressure (in) Min          14982 non-null  float64\n",
      " 40  Precipitation (in) Total   14982 non-null  float64\n",
      " 41  Departure_Hour             14982 non-null  int64  \n",
      " 42  delay_status               14982 non-null  object \n",
      " 43  delay_category             14922 non-null  object \n",
      " 44  airline.name               14982 non-null  object \n",
      " 45  departure.day_of_week      14982 non-null  int64  \n",
      "dtypes: float64(17), int64(8), object(21)\n",
      "memory usage: 5.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "status                           0\n",
       "departure.iataCode               0\n",
       "departure.icaoCode               0\n",
       "departure.scheduledTime          0\n",
       "departure.estimatedRunway     6252\n",
       "departure.actualRunway           0\n",
       "arrival.scheduledTime            0\n",
       "arrival.estimatedTime         6553\n",
       "airline.iataCode                 6\n",
       "airline.icaoCode                 1\n",
       "flight.number                    0\n",
       "flight.iataNumber                6\n",
       "flight.icaoNumber                1\n",
       "departure.terminal               0\n",
       "arrival.actualTime               0\n",
       "arrival.estimatedRunway      14907\n",
       "arrival.actualRunway             0\n",
       "departure.hour_of_day            0\n",
       "departure.month                  0\n",
       "status_encoded                   0\n",
       "Departure_Date                   0\n",
       "Departure_Month                  0\n",
       "Departure_Day                    0\n",
       "Month                         4622\n",
       "Day                           4622\n",
       "Temperature (°F) Max             0\n",
       "Temperature (°F) Avg             0\n",
       "Temperature (°F) Min             0\n",
       "Dew Point (°F) Max               0\n",
       "Dew Point (°F) Avg               0\n",
       "Dew Point (°F) Min               0\n",
       "Humidity (%) Max                 0\n",
       "Humidity (%) Avg                 0\n",
       "Humidity (%) Min                 0\n",
       "Wind Speed (mph) Max             0\n",
       "Wind Speed (mph) Avg             0\n",
       "Wind Speed (mph) Min             0\n",
       "Pressure (in) Max                0\n",
       "Pressure (in) Avg                0\n",
       "Pressure (in) Min                0\n",
       "Precipitation (in) Total         0\n",
       "Departure_Hour                   0\n",
       "delay_status                     0\n",
       "delay_category                  60\n",
       "airline.name                     0\n",
       "departure.day_of_week            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_df.info())\n",
    "test_X.info()\n",
    "test_X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc3b65-d6cb-4903-b1c3-b326b159b841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70bceef4-fcad-4310-80f4-9bd52d7b3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the Test Dataset\n",
    "test_df = pd.read_csv('merged_features_drop_cleaned_test_data.csv')\n",
    "\n",
    "# 2. Prepare Test Features\n",
    "test_X = test_df.drop(['departure.delay_minutes', 'binary_target', 'multi_target'], axis=1, errors='ignore')\n",
    "test_X = test_X[numeric_features + categorical_features]\n",
    "\n",
    "# 3. Create Required Columns for Submission\n",
    "\n",
    "# a. Create 'File Name'\n",
    "# Option 1: Using 'flight.number' as 'File Name'\n",
    "test_df['File Name'] = test_df['flight.number'].astype(str)\n",
    "\n",
    "# Option 2: Using a unique identifier\n",
    "# test_df['File Name'] = 'Test_' + test_df.index.astype(str)\n",
    "\n",
    "# b. Assign 'Flight Number'\n",
    "# Using 'flight.iataNumber' if preferred\n",
    "test_df['Flight Number'] = test_df['flight.iataNumber']\n",
    "\n",
    "# c. Assign 'Type'\n",
    "# Using 'departure.terminal' as an example; adjust based on competition's definition of 'Type'\n",
    "test_df['Type'] = test_df['departure.terminal']\n",
    "\n",
    "# d. Assign 'Status'\n",
    "test_df['Status'] = test_df['status']\n",
    "\n",
    "# e. Assign 'Departure IATA Code' and 'Departure ICAO Code'\n",
    "test_df['Departure IATA Code'] = test_df['departure.iataCode']\n",
    "test_df['Departure ICAO Code'] = test_df['departure.icaoCode']\n",
    "\n",
    "# f. Assign 'Scheduled Time' and 'Arrival Estimated Time'\n",
    "test_df['Scheduled Time'] = test_df['departure.scheduledTime']\n",
    "test_df['Arrival Estimated Time'] = test_df['arrival.estimatedTime']\n",
    "\n",
    "# g. Assign 'Arrival IATA Code' and 'Arrival ICAO Code'\n",
    "# If missing, assign 'UNKNOWN' or derive them\n",
    "if 'arrival.iataCode' in test_df.columns:\n",
    "    test_df['Arrival IATA Code'] = test_df['arrival.iataCode']\n",
    "else:\n",
    "    test_df['Arrival IATA Code'] = 'UNKNOWN'\n",
    "\n",
    "if 'arrival.icaoCode' in test_df.columns:\n",
    "    test_df['Arrival ICAO Code'] = test_df['arrival.icaoCode']\n",
    "else:\n",
    "    test_df['Arrival ICAO Code'] = 'UNKNOWN'\n",
    "\n",
    "# 4. Make Predictions Using Trained Models\n",
    "# Ensure that the following models are already trained:\n",
    "# - best_binary_model\n",
    "# - best_multi_model\n",
    "# - reg_pipeline\n",
    "\n",
    "test_pred_bin = best_binary_model.predict(test_X)\n",
    "test_pred_multi = best_multi_model.predict(test_X)\n",
    "test_pred_reg = reg_pipeline.predict(test_X)\n",
    "\n",
    "# 5. Create Submission Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95286b79-6bb6-4939-b581-16445dc9ad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification submission file created: 'submission_binary_classification.csv'\n",
      "Multi-Class Classification submission file created: 'submission_multi_classification.csv'\n",
      "Regression submission file created: 'submission_regression.csv'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'verify_submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError creating Regression submission: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 6. Verify Submission Files\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m verify_submission(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_binary_classification.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, submission_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m verify_submission(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_multi_classification.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, submission_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m verify_submission(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_regression.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, submission_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'verify_submission' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the submission creation function as above\n",
    "\n",
    "# a. Binary Classification Submission\n",
    "try:\n",
    "    submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "    submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "    print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Binary Classification submission: {e}\")\n",
    "\n",
    "# b. Multi-Class Classification Submission\n",
    "try:\n",
    "    submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "    submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "    print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Multi-Class Classification submission: {e}\")\n",
    "\n",
    "# c. Regression Submission\n",
    "try:\n",
    "    submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "    submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "    print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Regression submission: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4eca4-a23a-4ce7-8151-832e024aef39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7582116d-c1d7-40a7-b4e4-e06dcc2f0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a. Binary Classification Prediction\n",
    "# Ensure that 'best_binary_model' is already defined and trained\n",
    "test_pred_bin = best_binary_model.predict(test_X)\n",
    "\n",
    "# b. Multi-Class Classification Prediction\n",
    "# Ensure that 'best_multi_model' is already defined and trained\n",
    "test_pred_multi = best_multi_model.predict(test_X)\n",
    "\n",
    "# c. Regression Prediction\n",
    "# Ensure that 'reg_pipeline' is already defined and trained\n",
    "test_pred_reg = reg_pipeline.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39301380-cee8-48c9-abd6-b445869de56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'departure.iataCode', 'departure.icaoCode',\n",
       "       'departure.scheduledTime', 'departure.estimatedRunway',\n",
       "       'departure.actualRunway', 'arrival.scheduledTime',\n",
       "       'arrival.estimatedTime', 'airline.iataCode', 'airline.icaoCode',\n",
       "       'flight.number', 'flight.iataNumber', 'flight.icaoNumber',\n",
       "       'departure.terminal', 'arrival.actualTime', 'arrival.estimatedRunway',\n",
       "       'arrival.actualRunway', 'departure.hour_of_day', 'departure.month',\n",
       "       'status_encoded', 'Departure_Date', 'Departure_Month', 'Departure_Day',\n",
       "       'Month', 'Day', 'Temperature (°F) Max', 'Temperature (°F) Avg',\n",
       "       'Temperature (°F) Min', 'Dew Point (°F) Max', 'Dew Point (°F) Avg',\n",
       "       'Dew Point (°F) Min', 'Humidity (%) Max', 'Humidity (%) Avg',\n",
       "       'Humidity (%) Min', 'Wind Speed (mph) Max', 'Wind Speed (mph) Avg',\n",
       "       'Wind Speed (mph) Min', 'Pressure (in) Max', 'Pressure (in) Avg',\n",
       "       'Pressure (in) Min', 'Precipitation (in) Total', 'Departure_Hour',\n",
       "       'departure.delay_minutes', 'delay_status', 'delay_category',\n",
       "       'airline.name', 'departure.day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6d81ba2-6c31-4aa9-8123-d10fe4e37c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating Binary Classification submission: The following required columns are missing in test_df: ['File Name', 'Flight Number', 'Type', 'Status', 'Departure IATA Code', 'Departure ICAO Code', 'Scheduled Time', 'Arrival IATA Code', 'Arrival ICAO Code', 'Arrival Estimated Time']\n",
      "Error creating Multi-Class Classification submission: The following required columns are missing in test_df: ['File Name', 'Flight Number', 'Type', 'Status', 'Departure IATA Code', 'Departure ICAO Code', 'Scheduled Time', 'Arrival IATA Code', 'Arrival ICAO Code', 'Arrival Estimated Time']\n",
      "Error creating Regression submission: The following required columns are missing in test_df: ['File Name', 'Flight Number', 'Type', 'Status', 'Departure IATA Code', 'Departure ICAO Code', 'Scheduled Time', 'Arrival IATA Code', 'Arrival ICAO Code', 'Arrival Estimated Time']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Define a Function to Create Submission Files\n",
    "def create_submission(test_df, predictions, submission_type='binary'):\n",
    "    \"\"\"\n",
    "    Creates a submission DataFrame for Kaggle competition.\n",
    "\n",
    "    Parameters:\n",
    "    - test_df (pd.DataFrame): The test dataset.\n",
    "    - predictions (array-like): The predictions made by the model.\n",
    "    - submission_type (str): Type of submission ('binary', 'multi', 'regression').\n",
    "\n",
    "    Returns:\n",
    "    - submission (pd.DataFrame): The formatted submission DataFrame.\n",
    "    \"\"\"\n",
    "    # Define the required columns as per Kaggle's submission format\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time'\n",
    "    ]\n",
    "    \n",
    "    # Check if all required columns are present in test_df\n",
    "    missing_cols = [col for col in required_columns if col not in test_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"The following required columns are missing in test_df: {missing_cols}\")\n",
    "    \n",
    "    # Create the submission DataFrame with required columns\n",
    "    submission = test_df[required_columns].copy()\n",
    "    \n",
    "    # Assign the predictions to the 'Delay' column based on submission type\n",
    "    if submission_type == 'binary':\n",
    "        # Ensure predictions are strings: \"on-time\" or \"delayed\"\n",
    "        if not pd.api.types.is_string_dtype(predictions):\n",
    "            predictions = predictions.astype(str)\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'multi':\n",
    "        # Ensure predictions are strings: \"No Delay\", \"Short Delay\", etc.\n",
    "        if not pd.api.types.is_string_dtype(predictions):\n",
    "            predictions = predictions.astype(str)\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'regression':\n",
    "        # Ensure predictions are integers (minutes)\n",
    "        predictions = np.round(predictions).astype(int)\n",
    "        submission['Delay'] = predictions\n",
    "    else:\n",
    "        raise ValueError(\"Invalid submission_type. Choose from 'binary', 'multi', or 'regression'.\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# 5. Create Submission Files\n",
    "\n",
    "# a. Binary Classification Submission\n",
    "try:\n",
    "    submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "    submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "    print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Binary Classification submission: {e}\")\n",
    "\n",
    "# b. Multi-Class Classification Submission\n",
    "try:\n",
    "    submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "    submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "    print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Multi-Class Classification submission: {e}\")\n",
    "\n",
    "# c. Regression Submission\n",
    "try:\n",
    "    submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "    submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "    print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Regression submission: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00a501-69bc-4711-aa26-5adf47b02bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Verify Submission Files (Optional but Recommended)\n",
    "def verify_submission(file_path, submission_type='binary'):\n",
    "    \"\"\"\n",
    "    Verifies the submission file for correctness.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the submission CSV file.\n",
    "    - submission_type (str): Type of submission ('binary', 'multi', 'regression').\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    submission = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time',\n",
    "        'Delay'\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_columns if col not in submission.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Submission file {file_path} is missing columns: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    # Check for correct data types\n",
    "    if submission_type in ['binary', 'multi']:\n",
    "        if not submission['Delay'].dtype == object:\n",
    "            print(f\"'Delay' column in {file_path} should be of type object (string).\")\n",
    "    elif submission_type == 'regression':\n",
    "        if not np.issubdtype(submission['Delay'].dtype, np.integer) and not np.issubdtype(submission['Delay'].dtype, np.floating):\n",
    "            print(f\"'Delay' column in {file_path} should be numeric (int or float).\")\n",
    "    \n",
    "    # Check for missing values in 'Delay' column\n",
    "    if submission['Delay'].isnull().any():\n",
    "        print(f\"'Delay' column in {file_path} contains missing values.\")\n",
    "    \n",
    "    print(f\"Submission file {file_path} passed verification.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1f06e-8e86-436b-9529-0a57917e2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify each submission file\n",
    "verify_submission('submission_binary_classification.csv', submission_type='binary')\n",
    "verify_submission('submission_multi_classification.csv', submission_type='multi')\n",
    "verify_submission('submission_regression.csv', submission_type='regression')\n",
    "\n",
    "# ==============================================\n",
    "# End of Phase 5: Model Testing and Submission\n",
    "# ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3a009-1b22-4231-940a-72f8f072142a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46751670-5459-4c91-acd4-b4e1a273eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659e1ac-759a-4a71-b14d-b08f87f0c20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77673cc3-8eae-4fb6-be84-3d4f50695d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0202af-6569-45db-99ed-8c3383111fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5ce34-53d1-4f55-baf3-1cdc45531732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best performing model based on cross-validation scores\n",
    "# For demonstration, assume RandomForest performed best\n",
    "\n",
    "# ==============================================\n",
    "# PHASE 5: Model Testing and Submission\n",
    "# ==============================================\n",
    "\n",
    "# 1. Make Predictions on the Test Dataset\n",
    "\n",
    "# Prepare the test set features (ensure same preprocessing)\n",
    "test_X = X_test_full.drop(['departure.delay_minutes', 'binary_target', 'multi_target'], axis=1, errors='ignore')\n",
    "\n",
    "# Binary Classification Prediction using best_binary_model\n",
    "test_pred_bin = best_binary_model.predict(test_X)\n",
    "\n",
    "# Multi-Class Classification Prediction (if you have optimized multi-class model)\n",
    "# Assuming you have a best_multi_model (similar to best_binary_model)\n",
    "# For this example, we'll use the previously trained multi_clf_pipeline\n",
    "test_pred_multi = multi_clf_pipeline.predict(test_X)\n",
    "\n",
    "# Regression Prediction using reg_pipeline\n",
    "test_pred_reg = reg_pipeline.predict(test_X)\n",
    "\n",
    "# 2. Save Predictions in Kaggle Submission Format\n",
    "\n",
    "# Define a function to create submission files\n",
    "def create_submission(test_df, predictions, submission_type='binary'):\n",
    "    # Ensure that the necessary columns are present in test_df\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time'\n",
    "    ]\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    for col in required_columns:\n",
    "        if col not in test_df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    submission = test_df[required_columns].copy()\n",
    "    \n",
    "    if submission_type == 'binary':\n",
    "        # Convert predictions to string format\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'multi':\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'regression':\n",
    "        # Convert delay minutes to integer or keep as float based on Kaggle requirements\n",
    "        submission['Delay'] = predictions.round().astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid submission type. Choose from 'binary', 'multi', or 'regression'.\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# Create Binary Classification Submission\n",
    "submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "\n",
    "# Create Multi-Class Classification Submission\n",
    "submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "\n",
    "# Create Regression Submission\n",
    "submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "\n",
    "# ==============================================\n",
    "# Additional: Feature Importance Plot (Optional)\n",
    "# ==============================================\n",
    "\n",
    "# Plot feature importances for Binary Classification\n",
    "def plot_feature_importances(model, preprocessor, numerical_features, categorical_features, top_n=20):\n",
    "    # Get feature names after preprocessing\n",
    "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    ohe_features = ohe.get_feature_names_out(categorical_features)\n",
    "    feature_names = numerical_features + list(ohe_features)\n",
    "    \n",
    "    # Get feature importances from the model\n",
    "    importances = model.named_steps['classifier'].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=importances[indices][:top_n], y=np.array(feature_names)[indices][:top_n])\n",
    "    plt.title(f\"Top {top_n} Feature Importances\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot feature importances for best_binary_model\n",
    "plot_feature_importances(best_binary_model, preprocessor, numerical_features, categorical_features, top_n=20)\n",
    "\n",
    "# ==============================================\n",
    "# END OF SCRIPT\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba78557-2671-4c7d-80f9-864424212e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# PHASE 5: Model Testing and Submission\n",
    "##############################################\n",
    "\n",
    "# Use best models to predict on test set\n",
    "# Make sure test_df has the same preprocessing applied, i.e., same columns/features.\n",
    "test_X = test_df[numeric_features + categorical_features]\n",
    "\n",
    "# Example for Binary Classification Prediction on Test Set\n",
    "test_pred_bin = best_binary_model.predict(test_X)\n",
    "\n",
    "# For submission, ensure the format matches Kaggle's requirements\n",
    "submission = test_df[['File Name', 'Flight Number', 'Type', 'Status', \n",
    "                      'Departure IATA Code', 'Departure ICAO Code', \n",
    "                      'Scheduled Time', 'Arrival IATA Code', \n",
    "                      'Arrival ICAO Code', 'Arrival Estimated Time']].copy()\n",
    "\n",
    "# Delay must be string like \"on-time\" or \"delayed\"\n",
    "submission['Delay'] = test_pred_bin.astype(str)\n",
    "\n",
    "submission.to_csv('submission_binary_classification.csv', index=False)\n",
    "\n",
    "# For multi-class classification and regression, do the same:\n",
    "# test_pred_multi = multi_clf_pipeline.predict(test_X)\n",
    "# test_pred_reg = reg_pipeline.predict(test_X)\n",
    "\n",
    "# Then save their submissions accordingly, ensuring correct format and data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102346f-9147-47ac-a152-0694499fe980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cedd7-afe0-4e0e-a7f4-956a7136e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================\n",
    "# Phase 5: Model Testing and Submission\n",
    "# ==============================================\n",
    "\n",
    "# 1. Load the Test Dataset\n",
    "# Replace 'test.csv' with your actual test file path if different\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Make Predictions Using Trained Models\n",
    "# Assuming you have already made predictions and stored them in the following variables:\n",
    "# - test_pred_bin: Predictions for Binary Classification ('on-time' or 'delayed')\n",
    "# - test_pred_multi: Predictions for Multi-Class Classification ('No Delay', 'Short Delay', etc.)\n",
    "# - test_pred_reg: Predictions for Regression (delay in minutes)\n",
    "\n",
    "# For demonstration, let's assume the predictions are already made:\n",
    "# Uncomment and replace with your actual prediction code if not already done.\n",
    "\n",
    "# Example:\n",
    "# test_pred_bin = best_binary_model.predict(test_X)\n",
    "# test_pred_multi = best_multi_model.predict(test_X)\n",
    "# test_pred_reg = reg_pipeline.predict(test_X)\n",
    "\n",
    "# For the purpose of this example, let's create dummy predictions.\n",
    "# Remove these lines when you have actual predictions.\n",
    "# ---------------------------------------------------\n",
    "# test_pred_bin = np.random.choice(['on-time', 'delayed'], size=test_df.shape[0])\n",
    "# test_pred_multi = np.random.choice(['No Delay', 'Short Delay', 'Moderate Delay', 'Long Delay'], size=test_df.shape[0])\n",
    "# test_pred_reg = np.random.randint(0, 300, size=test_df.shape[0])\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 3. Define a Function to Create Submission Files\n",
    "def create_submission(test_df, predictions, submission_type='binary'):\n",
    "    \"\"\"\n",
    "    Creates a submission DataFrame for Kaggle competition.\n",
    "\n",
    "    Parameters:\n",
    "    - test_df (pd.DataFrame): The test dataset.\n",
    "    - predictions (array-like): The predictions made by the model.\n",
    "    - submission_type (str): Type of submission ('binary', 'multi', 'regression').\n",
    "\n",
    "    Returns:\n",
    "    - submission (pd.DataFrame): The formatted submission DataFrame.\n",
    "    \"\"\"\n",
    "    # Define the required columns as per Kaggle's submission format\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time'\n",
    "    ]\n",
    "    \n",
    "    # Check if all required columns are present in test_df\n",
    "    missing_cols = [col for col in required_columns if col not in test_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"The following required columns are missing in test_df: {missing_cols}\")\n",
    "    \n",
    "    # Create the submission DataFrame with required columns\n",
    "    submission = test_df[required_columns].copy()\n",
    "    \n",
    "    # Assign the predictions to the 'Delay' column based on submission type\n",
    "    if submission_type == 'binary':\n",
    "        # Ensure predictions are strings: \"on-time\" or \"delayed\"\n",
    "        if not pd.api.types.is_string_dtype(predictions):\n",
    "            predictions = predictions.astype(str)\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'multi':\n",
    "        # Ensure predictions are strings: \"No Delay\", \"Short Delay\", etc.\n",
    "        if not pd.api.types.is_string_dtype(predictions):\n",
    "            predictions = predictions.astype(str)\n",
    "        submission['Delay'] = predictions\n",
    "    elif submission_type == 'regression':\n",
    "        # Ensure predictions are integers (minutes)\n",
    "        predictions = np.round(predictions).astype(int)\n",
    "        submission['Delay'] = predictions\n",
    "    else:\n",
    "        raise ValueError(\"Invalid submission_type. Choose from 'binary', 'multi', or 'regression'.\")\n",
    "    \n",
    "    return submissiontest_pred_bin\n",
    "\n",
    "# 4. Create Submission Files\n",
    "\n",
    "# a. Binary Classification Submission\n",
    "try:\n",
    "    submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "    submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "    print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Binary Classification submission: {e}\")\n",
    "\n",
    "# b. Multi-Class Classification Submission\n",
    "try:\n",
    "    submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "    submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "    print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Multi-Class Classification submission: {e}\")\n",
    "\n",
    "# c. Regression Submission\n",
    "try:\n",
    "    submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "    submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "    print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Regression submission: {e}\")\n",
    "\n",
    "# 5. Verify Submission Files (Optional but Recommended)\n",
    "def verify_submission(file_path, submission_type='binary'):\n",
    "    \"\"\"\n",
    "    Verifies the submission file for correctness.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the submission CSV file.\n",
    "    - submission_type (str): Type of submission ('binary', 'multi', 'regression').\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    submission = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_columns = [\n",
    "        'File Name', 'Flight Number', 'Type', 'Status',\n",
    "        'Departure IATA Code', 'Departure ICAO Code',\n",
    "        'Scheduled Time', 'Arrival IATA Code',\n",
    "        'Arrival ICAO Code', 'Arrival Estimated Time',\n",
    "        'Delay'\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_columns if col not in submission.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Submission file {file_path} is missing columns: {missing_cols}\")\n",
    "        return\n",
    "    \n",
    "    # Check for correct data types\n",
    "    if submission_type in ['binary', 'multi']:\n",
    "        if not submission['Delay'].dtype == object:\n",
    "            print(f\"'Delay' column in {file_path} should be of type object (string).\")\n",
    "    elif submission_type == 'regression':\n",
    "        if not np.issubdtype(submission['Delay'].dtype, np.integer) and not np.issubdtype(submission['Delay'].dtype, np.floating):\n",
    "            print(f\"'Delay' column in {file_path} should be numeric (int or float).\")\n",
    "    \n",
    "    # Check for missing values in 'Delay' column\n",
    "    if submission['Delay'].isnull().any():\n",
    "        print(f\"'Delay' column in {file_path} contains missing values.\")\n",
    "    \n",
    "    print(f\"Submission file {file_path} passed verification.\")\n",
    "\n",
    "# Verify each submission file\n",
    "verify_submission('submission_binary_classification.csv', submission_type='binary')\n",
    "verify_submission('submission_multi_classification.csv', submission_type='multi')\n",
    "verify_submission('submission_regression.csv', submission_type='regression')\n",
    "\n",
    "# ==============================================\n",
    "# End of Phase 5: Model Testing and Submission\n",
    "# ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1e8f6-6954-4352-87ee-f7104323e306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74b7f8d8-9b30-4753-bbf4-10cc80cb9308",
   "metadata": {},
   "source": [
    "# sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c93e3b-38c6-4168-8031-c627118ad32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 5. Create Submission Files\n",
    "# ==============================================\n",
    "\n",
    "def create_submission(test_df, predictions, submission_type='binary'):\n",
    "    \"\"\"\n",
    "    Creates a submission DataFrame for Kaggle competition.\n",
    "\n",
    "    Parameters:\n",
    "    - test_df (pd.DataFrame): The test dataset.\n",
    "    - predictions (array-like): The predictions made by the model.\n",
    "    - submission_type (str): Type of submission ('binary', 'multi', 'regression').\n",
    "\n",
    "    Returns:\n",
    "    - submission (pd.DataFrame): The formatted submission DataFrame.\n",
    "    \"\"\"\n",
    "    # Create an 'ID' column starting from 1 for each row in the test dataset\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df.index + 1  # ID should be from 1, not 0\n",
    "    })\n",
    "\n",
    "    if submission_type == 'binary':\n",
    "        # Map the binary predictions to 'on-time' and 'delayed'\n",
    "        submission['Delay'] = np.where(predictions == 0, 'on-time', 'delayed')\n",
    "\n",
    "    elif submission_type == 'multi':\n",
    "        # Map multi-class predictions to 'No Delay', 'Short Delay', 'Moderate Delay', 'Long Delay'\n",
    "        # Assuming the model outputs values like 0, 1, 2, 3 for these categories\n",
    "        delay_map = {0: 'No Delay', 1: 'Short Delay', 2: 'Moderate Delay', 3: 'Long Delay'}\n",
    "        submission['Delay'] = [delay_map.get(pred, 'UNKNOWN') for pred in predictions]\n",
    "\n",
    "    elif submission_type == 'regression':\n",
    "        # For regression, the predictions are continuous, so directly assign the predicted delay\n",
    "        submission['Delay'] = predictions\n",
    "\n",
    "    # Ensure the submission format matches Kaggle requirements\n",
    "    submission = submission[['ID', 'Delay']]\n",
    "    return submission\n",
    "\n",
    "# a. Binary Classification Submission\n",
    "try:\n",
    "    submission_bin = create_submission(test_df, test_pred_bin, submission_type='binary')\n",
    "    submission_bin.to_csv('submission_binary_classification.csv', index=False)\n",
    "    print(\"Binary Classification submission file created: 'submission_binary_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Binary Classification submission: {e}\")\n",
    "\n",
    "# b. Multi-Class Classification Submission\n",
    "try:\n",
    "    submission_multi = create_submission(test_df, test_pred_multi, submission_type='multi')\n",
    "    submission_multi.to_csv('submission_multi_classification.csv', index=False)\n",
    "    print(\"Multi-Class Classification submission file created: 'submission_multi_classification.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Multi-Class Classification submission: {e}\")\n",
    "\n",
    "# c. Regression Submission\n",
    "try:\n",
    "    submission_reg = create_submission(test_df, test_pred_reg, submission_type='regression')\n",
    "    submission_reg.to_csv('submission_regression.csv', index=False)\n",
    "    print(\"Regression submission file created: 'submission_regression.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Regression submission: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d06b1f-3bf4-4758-a0f0-a01f7fe1933c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419904ad-aa9d-438a-bece-87e49dcf9374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970991-8e5d-4dd0-8bb2-471cc2f17613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450494b-6418-4948-92d7-edff5465686e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b7b0b-4b9c-4d9c-b161-1814d8cee729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e978e5f-fc29-4ec2-84df-a6d60f1012c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea087254-76e6-4df2-826a-410ac25d8884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0223105-3023-4239-8d51-8a9410d18ad5",
   "metadata": {},
   "source": [
    "# 1. Training the Model (for Binary Classification):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd730c4-cac9-4329-a33e-8da1202ba7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load and prepare your training data\n",
    "train_df = pd.read_csv('merged_features_drop_cleaned_train_data.csv')  # Load your training data\n",
    "\n",
    "# Ensure the training data has the correct number of rows\n",
    "train_df = train_df.head(12914)\n",
    "\n",
    "# Prepare features for training\n",
    "numeric_features = ['Temperature (°F) Avg', 'Humidity (%) Avg', 'Wind Speed (mph) Avg', 'Pressure (in) Avg']\n",
    "categorical_features = ['departure.iataCode', 'departure.icaoCode', 'airline.iataCode']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X_train = train_df[numeric_features + categorical_features]\n",
    "y_train = train_df['Delay']  # Assuming 'Delay' is the target column\n",
    "\n",
    "# Step 2: Preprocessing pipeline for categorical and numeric features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# Combine both numeric and categorical transformers in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 3: Define the pipeline with XGBoost classifier\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Step 4: Fit the binary classification model\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model for later use\n",
    "import joblib\n",
    "joblib.dump(xgb_pipeline, 'best_binary_model.pkl')\n",
    "\n",
    "# Now you can use 'best_binary_model' to make predictions on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f26a54-c968-4752-9f20-0ff7983ff54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f334a-b51e-46e3-bb04-0a6f732bf0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3705f8-f75e-4868-bd3b-8fa6fc7ecefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee3fe8-c884-49cf-a40a-6dc331dcdd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b2a1c-1a89-4078-bedb-502838f012cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f204f7-3456-4fc4-a5bc-ad43bb3b12f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
